<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Cyber Ape stories</title><link href="https://cyberape.space/en/" rel="alternate"></link><link href="https://cyberape.space/atom" rel="self"></link><id>https://cyberape.space/en/</id><updated>2023-12-12T00:00:00+00:00</updated><entry><title>Embeddings, Aufhebung &amp; Denkökonomie</title><link href="https://cyberape.space/en/embeddings.html" rel="alternate"></link><published>2023-12-12T00:00:00+00:00</published><updated>2023-12-12T00:00:00+00:00</updated><author><name>FunBotan</name></author><id>tag:cyberape.space,2023-12-12:/en/embeddings.html</id><summary type="html">&lt;p&gt;Connecting some dots between machine learning, neurobiology, and the 19th-century German philosophy&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;The problem with the contemporary discourse around AI is that there's a near-zero intersection between those who have been trying to analytically understand intelligence for millennia and those who went the "reverse-engineering" route. And the results are absolutely comical on both sides.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Machine learning perspective&lt;/h2&gt;
&lt;p&gt;Without knowing anything about the nature of colors, we may naively assume that each hue (red, green, blue, yellow, purple, etc.) exists independently of the others. However, having started mixing colors, we quickly (or not so quickly) come to the conclusion that there are only three truly independent colors: red, green, and blue, and all the rest are their &lt;em&gt;linear combinations&lt;/em&gt;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; (mixtures in different proportions).&lt;/p&gt;
&lt;p&gt;Even for those with little knowledge of mathematics, it should not be difficult to imagine colors as three-dimensional vectors (lists of three numbers). But what is the benefit of this representation? Firstly, we obtain a correspondence between the physical process of color mixing and arithmetic operations on vectors. Secondly, this representation is also maximally &lt;em&gt;compressed&lt;/em&gt;; it takes up the minimum possible amount of memory.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/embeddings/rgb.jpg"&gt;&lt;/p&gt;
&lt;p&gt;The example of colors is good precisely because we know the answer in advance. But there are many other classes of objects for which we would like to obtain a representation with similar properties, but how to do this is not at all obvious. One such class could be &lt;em&gt;words&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Again, we can start with the assumption that all words are independent of each other; that is, in the linear space of words, each of them corresponds to its own dimension (this approach is called one-hot encoding). But this assumption will quickly be shattered by fairly obvious examples of antonyms, such as “high - low,” “bright - dim,” “help - hinder,” “loud - quiet.” For each pair of antonyms, we can write down an equation of the form “high + low = 0”, “help + hinder = 0”, etc. In this way, we algebraically &lt;em&gt;express&lt;/em&gt; one word through another, which means we can eliminate one of the two dimensions originally allocated to them. Moreover, the right side of these equations needs not be zero. It could also be a non-zero vector: &lt;em&gt;another word&lt;/em&gt;. For example: “damp + cold = dank”, “irony + mockery = sarcasm”, “music + poetry = song”. Moving up a level to four words in one equation, we can begin to illustrate the different kinds of relationships between words. For example, “king - man + woman = queen” is a semantic relationship, and “big + less = small + more” is a syntactic one. These are just the simplest examples; there is no limit to the complexity of such constructs.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/embeddings/words.png"&gt;&lt;/p&gt;
&lt;p&gt;The problem is that considering all possible verbal equations for expressing words through each other and determining the relative positions of their corresponding vectors is a task that is far beyond reasonable in terms of labor intensity. Which is why it was solved only with the advent of machine learning. A breakthrough in word vectorization was the simply named &lt;a href="https://arxiv.org/abs/1301.3781"&gt;word2vec algorithm&lt;/a&gt;, published a decade ago. The general public probably remembers it from some meme-worthy examples of verbal equations:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;pig - oink + Santa = HO HO HO&lt;br&gt;
pig - oink + Woody Woodpecker = Yabba dabba doo&lt;br&gt;
pig - oink + Fred Flinstone = wassup&lt;br&gt;
pig - oink + Homer Simpson = D’oh&lt;br&gt;
pig - oink + Donald Trump = YOU’RE FIRED&lt;br&gt;
pig - oink + Einstein = E = mc2&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Along with machine learning, a new word has appeared to describe such vector representations of objects: &lt;strong&gt;embeddings&lt;/strong&gt;, also known as latent vectors, since the linear space they occupy is called &lt;strong&gt;latent space&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The algorithm for generating embeddings turned out to be rather indirect. It consists of training a model, usually a neural network, to &lt;em&gt;guess&lt;/em&gt; information. For example, in the case of words, we can remove one word from a sentence and have the model &lt;em&gt;predict&lt;/em&gt; what should be in its place. Embeddings are generated during the training process as the model’s internal representations of the data that it is processing. If this explanation was confusing, then you only have to remember one thing: the connection between embeddings and predictions. We will need this connection soon.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/embeddings/translation.png"&gt;&lt;/p&gt;
&lt;p&gt;An interesting property of language is that embeddings of words from different languages will form a very similar structure, and by overlaying the latent spaces of different languages, one can create a dictionary for translation between them &lt;em&gt;without a single example of actual translation&lt;/em&gt;. This property has been known for a long time, albeit in a different formulation, and was used by archaeologists to decipher dead languages long before machine learning. It indicates that embeddings are not arbitrary but are an objective property (or rather, a homomorphic image) of what they are encoding. So, in the limit, different methods for calculating embeddings of the same objects should theoretically converge to similar results.&lt;/p&gt;
&lt;p&gt;With the help of machine learning, we can calculate embeddings for anything, provided that we have a sufficient number of examples illustrating relationships between the objects in question. For example, texts can be used to construct word embeddings, but you can also embed higher-level structures: sentences, paragraphs, and entire articles. They will simply require many more examples. Images are a little more complicated, but if you've ever solved a captcha like "select all squares that contain X to prove you're not a robot", you've helped some corporation (most likely Google) create better image embeddings.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/embeddings/captcha.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Embedding technology is also a pillar of all breakthroughs in the field of artificial intelligence in recent years, which is not surprising: embeddings, in essence, are a portal between the real world of people and the digital world of machines. ChatGPT and other generative neural networks like Stable diffusion and Midjourney rely on them.&lt;/p&gt;
&lt;p&gt;And speaking of image-generating models, have you ever seen &lt;a href="https://www.youtube.com/results?search_query=latent+walk"&gt;videos&lt;/a&gt; that consist of images endlessly morphing into each other, often in disturbing ways? It is &lt;a href="https://keras.io/examples/generative/random_walks_with_stable_diffusion/"&gt;also possible&lt;/a&gt; to specify a starting and a final image, and a model will interpolate an uncannily smooth transition between them, no matter how different they are. The fact that this is possible means that there is a nearly infinite number of images in between any two. This notion of &lt;em&gt;something being between two images&lt;/em&gt; is the key to understanding the nature and limitations of creativity that contemporary generative AI exhibits.&lt;/p&gt;
&lt;p&gt;Because, large as it may be, the latent space mathematically cannot contain all possible images or texts: their numbers are many orders of magnitude higher, and the vast majority are just noise anyway. So, what does it contain? It includes all possible things you can get by recombining the pre-existing data in various ways. All possible results of such recombinations taken together are called the &lt;strong&gt;span&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So then, what makes the creativity of GenAI different from that of humans? GenAI is locked within the span of the data it was trained on. This span is mindbogglingly large and has enough samples that will appear original to us. On the other hand, not all human artwork is original either: most of it is also a remix of what came before. But a human can, at least in principle, create something outside this span. If this weren't the case, it would be impossible for human creativity ever to begin because there would be no initial span for the very first artists or writers to sample from.&lt;/p&gt;
&lt;p&gt;Of course, modern GenAI does much more than walk across the latent space: LLMs answer your questions, and image generation models create pictures from a textual description. But these abilities really just come down to doing fancier math in the latent space to find what the user is looking for more efficiently. The fundamental limit on GenAI creativity remains the same and will remain the same until we come up with a completely new technological paradigm for AI.&lt;/p&gt;
&lt;p&gt;The problem is that there is not even a universally accepted explanation for why the paradigm we currently have is working to the extent it does. However, one explanation that I personally subscribe to is the &lt;a href="https://en.wikipedia.org/wiki/Manifold_hypothesis"&gt;Manifold hypothesis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The simplest example of a (low-dimensional) manifold is a sphere. While the sphere itself is a 3D object, its surface is 2D, meaning that we can uniquely identify any point on it with only two numbers. And even if we are only given 3-dimensional vectors describing points on this sphere, given enough of them, we should be able to reconstruct the complete sphere and remap them to the two-dimensional surface.&lt;/p&gt;
&lt;p&gt;What the manifold hypothesis posits is that deep learning is doing exactly that. First, it assumes that all &lt;em&gt;naturally occurring and useful&lt;/em&gt; data intrinsically exist on low-dimensional manifolds inside the spaces where we find them: for example, meaningful sentences are a manifold within the space of all possible strings, and images we can recognize as pictures are a manifold within all possible combinations of pixels. The task of the neural network is then to find these manifolds and flatten them into linear spaces, which we already know as &lt;em&gt;latent&lt;/em&gt; spaces. In fact, the extracted and flattened manifold is nothing else than the already familiar &lt;em&gt;span&lt;/em&gt;, and the data points remapped to it are nothing else than &lt;em&gt;embeddings&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Applications and implications&lt;/h3&gt;
&lt;p&gt;By formal definition, embeddings are just vectors whose geometric distance is proportional to the similarity of the objects they represent (an isometric homomorphism, if you will). Essentially, computing embeddings is the task of &lt;em&gt;classifying&lt;/em&gt; objects and determining their degree of relatedness, whatever that means in each specific case.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/embeddings/sentences.png"&gt;&lt;/p&gt;
&lt;p&gt;This property of correspondence between geometrical distance in latent space and similarity of embedded objects can be leveraged to perform similarity search. First, you build a database of embeddings (called a vector database) as a key-value storage, with vectors being keys and original objects being values. Then, you can run any new object through the same model to obtain its embedding. Finally, you do a K-nearest-neighbors search on that embedding in the database and return the values corresponding to found keys. This is roughly how image search, facial recognition, and recommendation algorithms work. Even most text search engines already use embeddings to search not only for literal matches with the search query but also for texts that are similar in meaning but phrased differently. Such search is called &lt;em&gt;semantic&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/embeddings/vdb.png"&gt;&lt;/p&gt;
&lt;p&gt;But, as I briefly mentioned at the beginning, a side effect of computing embeddings is the compression of information&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;. And there is some reason to believe that this is not just a side effect but an &lt;em&gt;equivalent definition&lt;/em&gt; of embeddings. This reason is an incredibly interesting &lt;a href="https://aclanthology.org/2023.findings-acl.426/"&gt;article&lt;/a&gt;, which proposes a way to measure distance between texts using compression (based on the notion of &lt;a href="https://brilliant.org/wiki/kolmogorov-complexity/"&gt;Kolmogorov complexity&lt;/a&gt;), thereby allowing the use of compressed texts as quasi-embeddings. It then compares embeddings produced by the most powerful language models with a conventional Gzip archiver in the text classification task. Paradoxically, in many tests (especially on small samples and outside the training distribution), Gzip's performance came close to much more complex language models.&lt;/p&gt;
&lt;p&gt;If that made no sense to you, then here is the conclusion in simpler words. Classifying objects requires identifying their common features, but if we have found such features, then we no longer need to remember them for each object separately; it is enough to have one record for all objects of the same class. Conversely, the task of information compression requires a reduction of repeating sequences, which turn out to be common properties of objects. In other words, both tasks come down to &lt;em&gt;generalization&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;But notice that neither machine learning nor even embeddings themselves appear in the previous paragraph. This is because it uncovers a much more general principle that applies, among other things, to the human brain. Evidence of this can be found in research from the field of mind reading: this year alone, two sci-fi-level results were obtained there.&lt;/p&gt;
&lt;p&gt;The first is the &lt;a href="https://www.nature.com/articles/s41593-023-01304-9"&gt;semantic reconstruction of language&lt;/a&gt;: decoding heard, read, and even imaginary (internal) speech from brain scans. Remarkably, the developed system does not reproduce words exactly but in a slightly different formulation that preserves the general meaning, hence the “semantic” qualifier. This means that it reconstructs &lt;em&gt;the thoughts&lt;/em&gt; themselves and not, for example, the motor signals that the brain involuntarily sends to the tongue and larynx, even when it is not speaking out loud. But most interestingly, if the same system is used on a person who is watching a silent film, the result of decoding their thoughts will be a text description of the scenes of this film!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ai.meta.com/blog/brain-ai-image-decoding-meg-magnetoencephalography/"&gt;The second result&lt;/a&gt; is a similar system but for the reconstruction of images, visible or imaginary. Its properties are the same: the images do not match exactly, but they are similar in a rather curious way, reflecting what details the person is paying attention to.&lt;/p&gt;
&lt;p&gt;Both systems share a very similar architecture and contain two key elements:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generative neural network. Semantic language reconstruction uses GPT-1, and image reconstruction uses a diffusion model from the same class as Stable diffusion and Midjourney.&lt;/li&gt;
&lt;li&gt;A model of the subject’s brain, implemented as an artificial neural network that, based on data (text or picture), predicts what signals the brain that thinks about this data will produce. I was amazed by the fact that this is already possible: in theory, modeling the human brain should not be achievable with the current level of technology. However, the models exist, and they work. Even if this is just a rough approximation at the moment, the very fact that such an approximation is possible and useful makes a big difference in estimating the complexity of this problem. Fortunately, to obtain results, the model must be trained individually on each subject, which is impossible without their cooperation, so it’s yet too early to worry about the adoption of mind reading by states and corporations for nefarious purposes. &lt;em&gt;Yet.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The system works as follows. First, the generative neural network creates many different variations of text or images. These options are fed to the neural network that models the brain, and it generates corresponding signals. They are compared with real brain scans of the subject, and the most similar ones are selected. The data that generated these signals arrive at the output of the system as decoded results, but at the same time are transmitted back to the generative model, which generates suitable continuations to repeat the process.&lt;/p&gt;
&lt;p&gt;All this is strikingly reminiscent of the semantic search mechanism described above. If we treat brain states as analogs of embeddings, then the process of mind decoding is just a similarity search in the space of these embeddings. Indeed, earlier studies independently confirmed that &lt;a href="https://www.nature.com/articles/nature21692"&gt;the brain also uses the concept of latent space&lt;/a&gt;, and &lt;a href="https://proceedings.neurips.cc/paper/2018/file/99064ba6631e279d4a74622df99657d6-Paper.pdf"&gt;the process of memory consolidation in the hippocampus is strikingly similar to the computation of embeddings&lt;/a&gt;. Particularly amazing is a &lt;a href="https://arxiv.org/pdf/2112.04035.pdf"&gt;paper showing equivalence&lt;/a&gt; between the hippocampus model and transformers, a class of artificial neural networks that underlie recent breakthroughs in natural language processing (that’s what T in GPT stands for) and which were developed without any prior knowledge of neurobiology. So, science once again converged to a solution that nature had already invented&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;. But this raises another question: what problem was nature solving?&lt;/p&gt;
&lt;h2&gt;Neurobiological perspective&lt;/h2&gt;
&lt;p&gt;On the one hand, the adaptive value of the human brain cannot be overestimated (says a human brain, ha-ha), which means that its development should have been very strongly encouraged by natural selection. This is supported by the relatively rapid evolution of the human brain. On the other hand, biophysics imposes strict constraints on the parameters of the brain. These are, firstly, physical dimensions, limited by the constraint of having to be born. Secondly, the human brain already consumes a fifth of the body’s total energy, and energy in nature is a strictly limited resource, so there was no opportunity to freely increase its consumption until quite recently, by evolutionary standards, with the emergence of agriculture. Thus, we have a very acute contradiction between the need to increase the power of the brain and the limitations on the parameters by which this could be achieved. It then follows that &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5651807/"&gt;the evolution of the brain should have gone in the direction of increasing &lt;em&gt;efficiency&lt;/em&gt;&lt;/a&gt;. And indeed, it seems that &lt;a href="https://www.lesswrong.com/posts/xwBuoE9p8GE7RAuhd/brain-efficiency-much-more-than-you-wanted-to-know"&gt;it is already about as efficient as it can theoretically be&lt;/a&gt;. Many other human adaptations &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9197885/"&gt;that increase energy efficiency at the expense of brute force&lt;/a&gt; hint at the same direction.&lt;/p&gt;
&lt;p&gt;But how is this efficiency achieved? For the answer, we again have to turn to machine learning, which &lt;a href="https://arxiv.org/abs/1605.08104"&gt;found&lt;/a&gt; that if you constrain the model in the energy budget, it automatically produces a predictive coding mechanism: the same one that produces embeddings! Moreover, transferring this result from artificial neural networks to biological ones is not a leap of faith: we already know for sure that predictive coding mechanisms arise in almost any well-optimized part of the brain.&lt;/p&gt;
&lt;p&gt;Since humans spend most of their time communicating with others (or at least did so until they invented the damned Internet), optimizing social interaction has been a high priority for evolution. The result of this optimization was, on the one hand, a &lt;a href="https://pubmed.ncbi.nlm.nih.gov/12921766/"&gt;highly specialized language cortex&lt;/a&gt;, which &lt;a href="https://www.nature.com/articles/s41562-022-01516-2"&gt;constantly tries to predict what it will hear&lt;/a&gt;, and on the other, mirror neurons, which completely model the mental state of other people (and, with proper development, not only people), and therefore they inevitably operate with compressed representations, since no system can completely model itself.&lt;/p&gt;
&lt;p&gt;If you reflect on the subtleties of your own behavior, you may notice these systems at work every time you interact with information in any way. For example, when opening an article, you may semi-subconsciously glance at the author, and if you already know them, then your brain will quickly make a prediction of what you are going to read about using the information it remembered from previous articles by the same author. This decreases the energy required to process the text and makes the reading process less frustrating. But this may also lead you into an echo chamber.&lt;/p&gt;
&lt;p&gt;Incidentally, the part of your brain that makes this prediction works in a way not unlike a text generation neural network such as GPT, at least on the surface level. We &lt;a href="https://memory.ucsf.edu/symptoms/speech-language"&gt;know for a fact&lt;/a&gt; that generating speech or text is handled by a different brain structure than analyzing it: Broca’s area and Wernicke’s area, respectively. This is what the famous Hemingway’s advice "write drunk, edit sober" captures. This also hints at another limitation of contemporary generative language models, as well as at how to overcome it. Instead of trying to build one model that can, so to speak, write and edit at the same time, we should mimic the brain structure and develop a different type of model that works similarly to Wernicke’s area and then connect them.&lt;/p&gt;
&lt;p&gt;“What I cannot create, I do not understand,” said Richard Feynman. Conversely, the best way to understand something beyond any doubt is to create it. So then, isn’t the creation of artificial intelligence our most successful attempt to understand our own?&lt;/p&gt;
&lt;p&gt;From a theoretical point of view, all this fits perfectly into the system of general &lt;a href="https://en.wikipedia.org/wiki/Good_regulator"&gt;theorems&lt;/a&gt; formulated for all systems, including brains, within the framework of cybernetics. &lt;a href="http://www.hutter1.net/ai/aixigentle.htm"&gt;One of these theorems&lt;/a&gt; states that if we consider the subject and the world with which they interact as computers exchanging information, then making optimal decisions for the subject, which is equivalent to predicting the consequences of available actions, is reducible to the maximum compression of information about the world. Of course, it would be premature to transfer this theorem to the real world since it is based on a rather shaky assumption of universal computability. But it would be equally unwise to ignore its conclusion.&lt;/p&gt;
&lt;p&gt;And now, it's finally time to put everything together. Efficiency necessitates prediction, prediction necessitates generalization, generalization is equivalent to compression... And what is compression? It is the &lt;em&gt;efficiency&lt;/em&gt;&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt; of storing information! The loop is closed, which means that all these processes are equivalent to each other at a fundamental level!&lt;/p&gt;
&lt;h2&gt;Philosophical perspective&lt;/h2&gt;
&lt;p&gt;The conclusion derived above is, of course, not that new. Similar ideas have been put forward in many forms, starting perhaps from an Austrian philosopher &lt;a href="https://www.leopoldina.org/fileadmin/redaktion/Mitglieder/CV_Ernst_Mach_D.pdf"&gt;Ernst Mach&lt;/a&gt; and &lt;a href="https://plato.stanford.edu/entries/ernst-mach/#Sci"&gt;his scientific framework of &lt;em&gt;Denkökonomie&lt;/em&gt;&lt;/a&gt;, which literally translates to “economy of thought”, “economy” meaning savings or efficiency. At its core, this framework demands the simplest possible (most economical) explanation of observed facts in science; it's essentially a beefed-up version of Occam's Razor, which Mach also derived from biological necessity.&lt;/p&gt;
&lt;p&gt;But what do we mean by this complexity/economy quantitatively? One answer is explanatory power, which is expressed as a ratio of the number of observations a theory explains divided by the number of assumptions that it relies on and which are unprovable within it. This is usually enough to compare two theories within the same subject domain. In the context of statistical models, the number of assumptions can be replaced with the number of trainable parameters. But it is possible to generalize even further.&lt;/p&gt;
&lt;p&gt;Recall the concept of &lt;a href="https://brilliant.org/wiki/kolmogorov-complexity/"&gt;Kolmogorov complexity&lt;/a&gt; mentioned earlier. Based on it, a theoretical measure of complexity for scientific theories was suggested by Ray Solomonoff as part of his &lt;a href="https://www.lesswrong.com/posts/Kyc5dFDzBg4WccrbK/an-intuitive-explanation-of-solomonoff-induction#Solomonoff_s_Lightsaber"&gt;theory of inductive inference&lt;/a&gt;. This is, in essence, a mathematical formalism for Mach's philosophical framework. It, in turn, is the basis for &lt;a href="https://www.lesswrong.com/posts/DFdSD3iKYwFS29iQs/intuitive-explanation-of-aixi"&gt;AIXI&lt;/a&gt;: an algorithm that is supposedly capable of discovering the most economic theories automatically; in other words, an AGI. The only issue is that none of these things are computable, which is why they were never used in practice. Some, however, try to &lt;a href="https://arxiv.org/abs/1007.2049"&gt;approximate AIXI&lt;/a&gt;, and this avenue of research probably deserves more attention than it is currently getting.&lt;/p&gt;
&lt;p&gt;It is easy to see that scientific progress almost always goes in the direction of more economical theories, at least when considered &lt;em&gt;on a sufficiently long time scale&lt;/em&gt;. For example, when radioactivity was first described, it did not fit into existing physical theories at all. Initially, it had to be considered as a completely independent phenomenon, which, of course, is not economical in the short term. But new theories soon emerged, combining old physics with new phenomena into a single and more economical system, and at the same time explaining things that previously seemed inexplicable: why are stars burning, and where atoms come from. Mach himself likely developed his framework by trying to formalize this very observation.&lt;/p&gt;
&lt;p&gt;Ironically, most people who know about Denkökonomie today know it not from the source material but from the &lt;a href="https://en.wikipedia.org/wiki/Materialism_and_Empirio-criticism"&gt;critique of it penned by Lenin&lt;/a&gt;. Therefore, it wouldn’t be fair to proceed without addressing it first.&lt;/p&gt;
&lt;h3&gt;Lenin’s perspective&lt;/h3&gt;
&lt;p&gt;If we accept that (1) Denkökonomie is a &lt;em&gt;sufficient&lt;/em&gt; criterion of truth and (2) the brain always strives for the most economical explanation of observed facts, then it follows that all people, as they gain experience, should converge on identical ideas about the world. But empirically, this obviously does not happen. This contradiction can be explained in two ways. The way that Mach chose was to deny the materiality of the world. Indeed, if each observer analyzes their own world, then there is no basis for consistency between their models of those worlds. Thus, Mach eventually reasoned himself into solipsism by an overly extreme application of his own principle.&lt;/p&gt;
&lt;p&gt;But ironically, a much more &lt;em&gt;economical&lt;/em&gt; way to explain the same contradiction is to abandon one of Mach's postulates. Since postulate 2 is now backed by science (as explained above), the problem is obviously in postulate 1. That is, Denkökonomie is not a sufficient but a necessary criterion of truth. Put simply, this means the truth cannot be found by following simplicity alone (string theory and supersymmetry empirically demonstrated this), but somehow, the truth always turns out to be simple.&lt;/p&gt;
&lt;p&gt;Having asserted that, we are left with the problem of coordination between the brain and the world outside it. To fill that gap, Lenin developed the dialectical materialist reflection theory, which became the model of intelligence in Marxism. The theory of reflection by itself is much older and simpler than Marxism and, at the base level, alleges that while we can only access objective reality through sensations, the results of these sensations are normally consistent with reality itself. Were they not, there would be no adaptive value in having the sensations and they would have never evolved in the first place. In other words, we have an internal model of reality in our minds that is being constantly clarified and grounded by sensations. The process of perception is then a transformation of a thing-in-itself into a thing-for-us through reflection.&lt;/p&gt;
&lt;p&gt;The problem is that any kind of reflection theory has a hard time explaining specifically how this process of transformation works since the thing-in-itself is obviously far more complex and detailed than the thing-for-us. The vast majority of information is necessarily lost in this process of transformation, so the question is: what is retained?&lt;/p&gt;
&lt;p&gt;For Lenin, the answer is that the information we retain is what is &lt;em&gt;useful in practice&lt;/em&gt;. Although usefulness is rather subjective as it heavily depends on the goal of the actor, many actors pursuing different goals eventually arrive at similar representations of the world. Thus, the process of reflection converges and becomes deterministic in the limit.&lt;/p&gt;
&lt;p&gt;Take a map as an example. If you download a map of the greater Berlin from Google Maps, it takes up a mere 100 megabytes: less than 30 bytes per capita (what a unit, huh). In that space, Google fits pretty much all the information you will realistically need to live in the city, and yet no one would argue that it encompasses the full experience of Berlin. This trick works because society has developed many useful abstractions, such as roads and buildings, which can be represented with only a few numbers each.&lt;/p&gt;
&lt;p&gt;And what do I need a map of Berlin for? To &lt;em&gt;predict&lt;/em&gt; where a specific train will take me or where I will end up after turning left or right at a specific intersection. So, usefulness is essentially a proxy for predictive power, and it is also connected with compression.&lt;/p&gt;
&lt;p&gt;But this connection goes both ways. We capture the compressible aspects of reality, but then we also use the understanding of these aspects to shape reality itself to be more compressible, like building straight roads and rectangular houses. This idea, if extrapolated, has some surprising and potentially useful implications.&lt;/p&gt;
&lt;h3&gt;A surprise detour into the Fermi paradox&lt;/h3&gt;
&lt;p&gt;Imagine we are writing software for an &lt;a href="https://www.astronomy.com/science/breakthrough-starshot-a-voyage-to-the-stars-within-our-lifetimes/"&gt;interstellar microprobe&lt;/a&gt; that will be launched to perform close-up imaging of a potentially inhabited exoplanet. Problem is, we cannot transmit the image back home for analysis: the probe has neither the antenna size nor the power budget for that. All we can send back is a single number: the probability that the planet hosts a technological civilization. How do we compute it?&lt;/p&gt;
&lt;p&gt;Leaning on what was said in the previous section, we can assume that aliens, like us, will build regular (and therefore compressible) structures, because they, no matter who "they" are, will find regularity more &lt;em&gt;useful&lt;/em&gt; than chaos. And, luckily for our probe's processor, this regularity can be easily measured without any assumptions about the form and function of structures on an image by simply calculating its &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy"&gt;entropy&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Long-time readers know that I've long been obsessed with the Fermi paradox, and specifically with deriving an answer to it from the definition of intelligence. In &lt;a href="https://cyberape.space/content/pages/black-attractor/paper.pdf"&gt;my paper on the topic&lt;/a&gt; I started with three different definitions and then expressed them through each other (so far only in the limit). And it is no coincidence that entropy was also the thread connecting these definitions.&lt;/p&gt;
&lt;p&gt;But let us also consider counterarguments to my proposition, which can me made from both sides.&lt;/p&gt;
&lt;p&gt;On the one hand, not everything that is compressible is artificial. Simple periodic patterns often occur in nature without life being involved, such as snowflakes or &lt;a href="https://askanearthspacescientist.asu.edu/top-question/columnar-jointing"&gt;basalt columns&lt;/a&gt;. Crystals in general are great at making these and, given the right conditions, could form structures visible from space. Then there are fractals: a class of patterns that are extremely compressible and are widely used in both nature and technology.&lt;/p&gt;
&lt;p&gt;On the other hand, the highly regular structures that we are building today require lots of effort to maintain. It is possible to imagine that, as technology evolves in the direction of self-replication and self-maintenance, technological structures become chaotic again, converging with nature. This idea has lots of potential for further development, and I hope to come back one day to give it a good think.&lt;/p&gt;
&lt;h3&gt;Platonic perspective&lt;/h3&gt;
&lt;p&gt;Slightly earlier I made an unsubstantiated claim that the category of &lt;em&gt;"useful"&lt;/em&gt; information is, in the limit, independent of the goal for which it is used. This, if true, is a deep and fundamental conclusion about the structure of reality itself, so it requires some justification.&lt;/p&gt;
&lt;p&gt;It is a well-known empirical fact in the deep learning community that training a model on the task you actually want to perform is not always a great start. Often it benefits to first train it on a more general task (known as pretraining) before specializing it to your specific use case (known as fine-tuning). For example, a language model that is first trained to understand multiple languages and then fine-tuned to translate between them performs much better compared to the same model trained on examples of translation from the start. And you can understand why, if you scroll back to the example of word embeddings for two languages overlayed on each other. This implies that the same representations of data are useful for many different tasks, in other words, they &lt;em&gt;converge&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This convergence for language and vision models has been recently measured in an already famous paper &lt;a href="https://arxiv.org/abs/2405.07987"&gt;"The Platonic Representation Hypothesis"&lt;/a&gt;. ChatGPT-4o heavily leverages it by using the same internal representations for different data types. There are also examples of representations convergence that are much harder to comprehend, such as a &lt;a href="https://www.simonsfoundation.org/event/the-next-great-scientific-theory-is-hiding-inside-a-neural-network/"&gt;model for solving partial differential equations that performs better after pretraining on... cat videos?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is hopefully enough to show that the convergence of representations between different tasks is empirically real. On the theoretical side, the explanation of this effect is offered again by the Manifold hypothesis. If real (or &lt;em&gt;useful&lt;/em&gt;) data always lies on low-dimensional latent manifolds, then jumping from one manifold to another (fine-tuning) will always be easier than finding the manifold in random noise, which is the alternative to pretraining.&lt;/p&gt;
&lt;p&gt;On the philosophical side, this looks a lot like Platonic idealism, which posits the existence of Forms: ideal representations that precede and give rise to material objects. Similar ideas can be found in Eastern philosophies. While this does not imply that we need to reject materialism in favor of objective idealism, it definitely posits some questions that will be very hard to answer from the materialistic perspective. But I am sure that it will be worth it.&lt;/p&gt;
&lt;p&gt;And if we once again allow ourselves to make analogies between neural networks and human brains, then this conclusion gives us an interesting perspective on the education system. I often hear people complaining about learning trigonometry in school, which no one ever uses after graduation. And fair enough, even I, a professional mathematician, rarely use it (and certainly look up trig identities instead of trying to dig them from the depth of memory). What is the point of learning such seemingly useless things? Could this be a form of pretraining that helps in life later in ways we do not consciously recognize? I suspect so, because people who did not graduate school empirically end up performing worse in a wide range of tasks, meaning that the school definitely does something useful. We just don't have the language to explain what remains in the head of an educated person after all the trig identities, poems and historical dates are no longer there.&lt;/p&gt;
&lt;h3&gt;Copernican perspective&lt;/h3&gt;
&lt;p&gt;I must add, however, that there are situations where Denkökonomie &lt;em&gt;can&lt;/em&gt; be used as a criterion of truth, namely, all else being equal. For example, if we put ourselves in the shoes of people who do not yet know about Newton's theory of universal gravitation, then how should we choose between the geocentric and heliocentric cosmological models? Both give fairly accurate predictions, so it is impossible to reject one of them by experiment alone. What is the difference between them? The heliocentric model uses a fixed and small number of parameters to describe orbits, while the geocentric model, in order to achieve the same accuracy, requires winding epicycles onto epicycles, thereby generating many more parameters. Later, Joseph Fourier invented one of the most powerful tools of mathematics: the Fourier transform, which allows one to describe &lt;em&gt;any&lt;/em&gt; trajectory or signal in a similar way. Hence, the geocentric model is bad not because it is incorrect but because it does not actually contain information about the motion of the planets: all this information is stored in its parameters. The heliocentric model &lt;em&gt;compresses&lt;/em&gt; this information, &lt;em&gt;saving&lt;/em&gt; parameters, and this is what makes it preferable. In other words, the heliocentric model has greater explanatory power.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/embeddings/centrism.png"&gt;&lt;/p&gt;
&lt;p&gt;While we should strive to use “Copernican modeling” wherever possible, there are problems where this approach fails, and we are forced to resort to “Ptolemaic modeling.” Statistics and machine learning are essentially sciences that study how to do it properly.&lt;/p&gt;
&lt;p&gt;The price for using over-parametrized modeling is usually the model's inability to &lt;em&gt;generalize&lt;/em&gt;. In order to at least somewhat regain it, regularization and dimensionality reduction methods were invented. They can be described as artificially limiting the complexity of the model in terms of the number of parameters or their values, in essence, forcing the model to be more &lt;em&gt;economical&lt;/em&gt;. These methods come dangerously close to using Denkökonomie as a &lt;em&gt;sufficient&lt;/em&gt; criterion of truth, but practice shows that they work, and it is practice that is the ultimate criterion of truth.&lt;/p&gt;
&lt;h3&gt;Hegelian perspective&lt;/h3&gt;
&lt;p&gt;But let us return to the contradiction in Mach's philosophy. Even having rejected Denkökonomie as a sufficient criterion of truth, we are still left with the question: why do different people come to completely different ideas about the world if its economical (compressed) representation, which the brain seeks to find, must be objective and independent of the observer? To answer this, we will have to turn to another branch of philosophy: dialectics.&lt;/p&gt;
&lt;p&gt;What we need from dialectics specifically is the concept of “&lt;a href="https://en.wikipedia.org/wiki/Aufheben"&gt;&lt;em&gt;Aufhebung&lt;/em&gt;&lt;/a&gt;,” which I will translate as “overcoming,” although no perfect translation to English exists. A classic example that demonstrates this concept is found in the relationship of the general theory of relativity and quantum mechanics with classical mechanics. These more advanced theories extend beyond classical mechanics, yet they also preserve it as a special case in the limit: when the speed of light approaches infinity and the Planck constant approaches zero, respectively. Technically, we can say that these theories are &lt;em&gt;contradictory&lt;/em&gt; because, &lt;em&gt;empirically,&lt;/em&gt; the speed of light is not infinite, and Planck's constant is not zero. However, the important thing is that more advanced theories can usually simulate less advanced ones through similar thought experiments.&lt;/p&gt;
&lt;p&gt;The procedure of dialectical overcoming is invaluable in theoretical disputes, where the opponent will always present facts that do not fit into your theory. If you cannot use it, you will eventually find yourself sandwiched between two losing options: challenging the facts and removing the facts from the scope of your theory. But the ability to overcome such contradictions not only allows you not to lose an argument but also turns the dispute into a full-fledged research activity that can potentially lead to new discoveries. In such a dispute, truth can really be born.&lt;/p&gt;
&lt;p&gt;However, the easiest way to trace the process of dialectical overcoming is not in discussions between different people but in the process of development of a single person: oneself. Each of us, in the depths of our closets or hard drives, has some notes from ancient times, looking at which we can &lt;s&gt;die of cringe&lt;/s&gt; understand how our worldview developed. And the basic law of this development is the preservation of previous versions of ourselves that we overcame. We never throw away all previous experience to start from scratch. Even when radically changing our views, in the new ones, we retain an imprint of the old ones, which strengthens them. For example, it allows us to argue for the new worldview much more competently compared to those for whom it is the starting point. The same logic explains &lt;a href="https://bigthink.com/mind-brain/antifragility/"&gt;the &lt;em&gt;antifragility&lt;/em&gt; of the human mind&lt;/a&gt;: it is by &lt;em&gt;overcoming&lt;/em&gt; (in a dialectical sense) pain and hardship that we become better as people. And I also believe that somewhere here lies the answer to the &lt;a href="https://www.cs.uic.edu/~liub/lifelong-learning/continual-learning.pdf"&gt;problem of continual learning&lt;/a&gt;, but extracting it will take some more work.&lt;/p&gt;
&lt;p&gt;For the same reason, not a single generally accepted theory in modern positive science can be &lt;em&gt;refuted&lt;/em&gt;. The only way to advance further in knowledge is to &lt;em&gt;overcome&lt;/em&gt; the old theory, that is, to find a more general theory, a special case of which will be the old one. But since generalization, as we found out above, is equivalent to compression, it turns out that &lt;em&gt;the result of dialectical overcoming should be more economical&lt;/em&gt;. And since dialectical overcoming is also a process of removing contradictions, the converse proposition can be formulated: &lt;em&gt;the more economical our theories are, the fewer contradictions there are between them&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The same logic explains why persuading people generally doesn't work. It is impossible to produce an “embedding” that can natively integrate into another person's “latent space” without access to their subjective experience, which is inaccessible to us by definition. Only I myself can convince myself of something, either in order to resolve the contradiction in my current model of reality or &lt;a href="https://therussiaprogram.org/ps_lab_1"&gt;under the influence of material factors&lt;/a&gt;. Socrates’ “maeutics” is based on the first option: it consists of identifying contradictions in the interlocutor’s worldview and making them obvious. Sometimes, this leads to the interlocutor reflecting and changing their opinion in order to resolve the contradiction. However, it is impossible to guarantee persuasion, let alone in a specific direction. Socrates was fine with that: in his gnoseology, each person already contained true knowledge about the world a priori, and all he had to do was to extract it. But that view leads to the same dead end in which Mach later ended up.&lt;/p&gt;
&lt;p&gt;Another significant drawback to this architecture is that it’s &lt;em&gt;monolithic&lt;/em&gt;, meaning that it’s impossible to transfer a part of knowledge from one model to another. Returning to the example of embeddings, we can see a manifestation of this problem in that the embeddings themselves are useless without the model that generated them. For the same reason, it is impossible to simply “download” the knowledge accumulated by humanity into the brain of an individual person. Each brain is a new model, and each must independently build its “latent space” from scratch. For this, it must conceptually go through the path that its predecessors already took (this is indirectly confirmed by the above studies on mind reading, where a model must be fitted to each subject). The development of a person repeats in miniature the development of the entire civilization in which they happened to be born. This, by the way, imposes an unpleasant limitation on science itself: sooner or later, the time required to retrace the path of humanity, even in its most compressed form, will exceed life expectancy, and new generations simply will not have enough time to create something original; therefore, artificial life extension or other ways of overcoming this limitation (e.g., hiveminds) will become a necessary condition of further progress. But today may be too early to worry about it.&lt;/p&gt;
&lt;h2&gt;The dialectical discussion method&lt;/h2&gt;
&lt;p&gt;After reading all of the above, I bet you’d never guess what question prompted all of this research. That question was: how do we hold discussions on complex topics and reach useful outcomes at their end? I will call this "the dialectical discussion method" since this name seems unoccupied and formulate it as a set of rules.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The first rule of dialectical discussion&lt;/strong&gt; is never to assume that any party in an argument can &lt;em&gt;be absolutely&lt;/em&gt; right or wrong. In dialectical terms, "everyone is a bearer of a relative truth." In general, each person develops a model of reality that explains their subjective experience, and this experience, in turn, reflects only a very limited patch of objective reality. Such limited models may well be internally consistent but, at the same time, mutually exclusive. All existing discussion methods are useless in such a situation: the interlocutors cannot accuse each other of contradictory beliefs, yet at the same time, they cannot find any common ground on which some kind of compromise could be built.&lt;/p&gt;
&lt;p&gt;And here, a previously derived conjecture comes to the rescue: "The more economical our theories are, the fewer contradictions there are between them." In terms of models and dialectics, it can be rephrased as follows: &lt;em&gt;the dimensionality of the model that overcomes the contradiction is smaller than the dimensionality of the contradictory models&lt;/em&gt;. The last time we talked about dimensionality was in the context of regularization. And this leads us to the &lt;strong&gt;second rule of dialectical discussion&lt;/strong&gt;: &lt;em&gt;regularization of theses&lt;/em&gt;. By analogy with machine learning, we have two complementary ways of implementing it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The first, analogous to the dimensionality reduction, is the removal of redundant concepts. Before proceeding to the logical analysis of the theses, it is necessary, within reason, to minimize the number of concepts used in the theses of both interlocutors by expressing some concepts through others. This will also help ensure that participants understand all the concepts being used. The best-case scenario also includes the introduction of new concepts that generalize others and reframe the contradiction in such a way that a solution to it becomes self-evident.&lt;/li&gt;
&lt;li&gt;The second, similar way, roughly corresponds to Sagan's rule: "Extraordinary conditions require extraordinary evidence."&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Finally, &lt;strong&gt;the third rule of dialectical discussion&lt;/strong&gt;, inextricably linked with the second, can be formulated as follows: "&lt;em&gt;At each stage of the discussion, there must be an opportunity for an external observer to enter into it, without studying the entire conversation as a prerequisite&lt;/em&gt;." At first glance, this rule may sound arbitrary, but in fact, it is nothing more than an adaptation of a famous maxim that often emerges in the positive sciences:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A mathematical theory is not to be considered complete until you have made it so clear that you can explain it to the first man whom you meet on the street.&lt;/p&gt;
&lt;p&gt;— David Hilbert&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The same idea has been formulated many times by scientists in various ways. I will not miss the opportunity to recommend once again Feynman's essay "Is Electricity Fire?" from the book "Surely You're Joking, Mr. Feynman!". It describes the likely origins of this maxim: when discussions are held in a "closed space," they tend to accumulate a hidden structure, which the interlocutors themselves are not aware of but which prevents them from arriving at the right answers. This can be counteracted in different ways. The best case scenario is when the participants themselves hold models of that "first man whom you meet on the street" in their heads and constantly explain their theses to this model, a kind of advanced self-criticism. In the general case, though, we should not count on this, so criticism should come from outside. One option is to actually bring new people into the discussion at every turn and force the discussants to involve them in the course of things. Alternatively, they could compile summaries/digests of their theses and publish them in the public domain.&lt;/p&gt;
&lt;p&gt;At the moment, the rules of dialectical discussion are purely theoretical in nature. Therefore, the next step is to test them in the field.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Actually, colors form not a linear space but a symmetry group SU(3). However, in the interval [0;1], it behaves in the same way as a linear space, and it is in this interval that we usually work with colors. Just be careful with subtraction.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Here, I deliberately omit the rather important difference between lossless and lossy compression. Most embedding models are not designed to restore the original object using the embedding itself, i.e., if they implement compression, it is very lossy. But this clarification becomes unnecessary when we move on to the discussion of human memory, in which these two types of information storage differ more quantitatively than qualitatively.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;You can also recall the story of convolutional neural networks (CNN), which replicate the structure of the mammalian visual cortex. But in this case, people &lt;a href="https://doi.org/10.1162/jocn_a_01544"&gt;deliberately “copied” an architecture from nature&lt;/a&gt;, which is much less interesting than the independent (convergent) emergence of the same architecture in nature and technology.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;Here I can be accused of substituting the thesis: at the beginning, it was about minimizing thinking, and at the end about minimizing memory. But these things are quite related. Once an economical (compressed) model has been created, cognitive operations with it also simplify, becoming more economical.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Пост"></category></entry><entry><title>Nothing personal, just business</title><link href="https://cyberape.space/en/war.html" rel="alternate"></link><published>2022-03-13T00:00:00+00:00</published><updated>2022-03-13T00:00:00+00:00</updated><author><name>FunBotan</name></author><id>tag:cyberape.space,2022-03-13:/en/war.html</id><summary type="html">&lt;p&gt;Looking for the reasons behind the unreasonable&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;People always have been the foolish victims of deception and self-deception in politics, and they always will be, until they have learned to seek out the interests of some class or other behind all moral, religious, political and social phrases, declarations and promises.&lt;/p&gt;
&lt;p&gt;— Vladimir Lenin&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Easy as it is to apply this great principle in hindsight, to events long past and well studied. It's another matter entirely to do so in a state of shock and awe that we have all found ourselves in the morning of February 24, 2022.&lt;/p&gt;
&lt;p&gt;At first glance, it may seem that the invasion of Ukraine by Russia cannot possibly have a rational, materialistic justification. Too high are the costs Russia will have to pay even in the case of total victory (which itself is becoming less and less plausible by the day), let alone in the case of defeat. What could possibly motivate the Russian ruling class to go for broke to this extent?&lt;/p&gt;
&lt;p&gt;It's no secret that the &lt;a href="https://atlas.cid.harvard.edu/explore?country=186&amp;amp;product=undefined&amp;amp;year=2019&amp;amp;productClass=HS&amp;amp;target=Product&amp;amp;partner=undefined&amp;amp;startYear=undefined"&gt;primary exports of Russia are oil and gas&lt;/a&gt;. Revenue from their sale comprises half of the state budget and 30% of GDP. The Russian regime has put all of its bets on the carbon horse, &lt;a href="https://www.rt.com/business/541415-russia-oil-reserves-decline/"&gt;and now that horse is getting tired&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To understand how Ukraine comes into the picture, we need to go back to 2012, when &lt;a href="https://www.iene.gr/6thSEEED/articlefiles/sessionIII/Hutta.pdf"&gt;huge offshore gas deposits were discovered in its territorial waters around Crimea&lt;/a&gt;. Around the same time, fracking was developed in the USA, which opened access to &lt;a href="http://shalegas.in.ua/en/shale-gas-resources-in-ukraine/"&gt;shale gas deposits under Donbas and Transnistria&lt;/a&gt;. Can it be just a coincidence that the same regions have the highest levels of ethnic tensions and separatist sentiments?&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/war/basis.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Ukraine, however, lacked the domestic capital and technology to extract all these resources. This naturally pushed the Ukrainian capital into the embrace of the American one: &lt;a href="https://www.offshore-technology.com/uncategorised/newsexxon-consortium-ukraine-skifska-oil-gas-field/"&gt;Yanukoviche's government began issuing drilling permits to such companies as Shell and Exxon&lt;/a&gt;. Had the Russian capital left the situation to be handled by the "invisible hand of the market," Ukraine might have become the second-largest exporter of gas in Europe in a few years, or maybe even push Russia out of the market: Western Europe would have preferred to buy gas from convenient Ukraine rather than wild and unpredictable Russia. And from there, it wouldn't be a stretch to imagine Ukraine in the EU or even NATO.&lt;/p&gt;
&lt;p&gt;Had Yanukovich and his clique retained their power, they would broker a deal with Russian capital. But then 2014 happened: American capital had openly entered the game, raising the stakes tremendously. Russia replied by &lt;a href="https://euromaidanpress.com/2018/10/10/black-sea-gas-deposits-an-overlooked-reason-for-russias-occupation-of-crimea/"&gt;annexing Crimea&lt;/a&gt; and &lt;a href="https://www.bbc.com/ukrainian/ukraine_in_russian/2015/12/151216_ru_s_ukraine_russia_sea"&gt;immediately proceeding with offshore drilling in its waters&lt;/a&gt;. As for the shale deposits, &lt;a href="https://www.euractiv.com/section/energy/opinion/russia-s-silent-shale-gas-victory-in-ukraine/"&gt;their development was effectively stalled by civil war&lt;/a&gt;, which Russia was satisfied with at the time: it didn't have the fracking technology to begin with.&lt;/p&gt;
&lt;p&gt;Just to relieve any doubts, in 2014, &lt;a href="https://tass.ru/mezhdunarodnaya-panorama/6964280"&gt;Joe Biden had placed his son on the board of directors of the largest Ukrainian oil and gas holding&lt;/a&gt;. Also, &lt;a href="https://vesma.today/news/post/36142-ukrainskiy-milliarder"&gt;one Ukrainian oil oligarch has committed suicide shortly after the war started&lt;/a&gt;, which might not prove anything by itself, but fits quite nicely into the bigger picture.&lt;/p&gt;
&lt;p&gt;Why were the Russian elites waiting for eight years to continue the war? That's not entirely clear at the moment. One plausible reason is the unprecedented growth of gas prices in Europe, which made imposing sanctions harder for the European economy than ever. Another possibility is the dire need for fresh water in Crimea: not coincidentally, &lt;a href="https://youtu.be/Gi6EYIS7isk"&gt;one of the first targets of the Russian military was the dam blocking the North-Crimean canal&lt;/a&gt;. The peninsula wouldn't survive another 2020-level drought. Ironically, the reason behind the severity of that drought was climate change, which is a direct effect of the very industry that fuels Russian aggression.&lt;/p&gt;
&lt;p&gt;Beside that, in 2005, 80% of Russian gas exports to Europe were pumped through pipelines lying in Ukraine, which were only supposed to be decommissioned by 2024. Despite the war, &lt;a href="https://ria.ru/20220301/gaz-1775733192.html"&gt;these pipelines are still working&lt;/a&gt;, and &lt;a href="https://www.gazprom.ru/investors/disclosure/actual-supplies/"&gt;their utilization is only growing&lt;/a&gt; along with gas prices. Apparently, the Russian capital has deemed Nord Stream 2 an acceptable sacrifice for regaining control over the older pipes that Ukrainians will no longer demand a transit fee to use. And even if a stray shell bursts a pipe here or there, it will only further raise gas prices, making the whole affair even more profitable.&lt;/p&gt;
&lt;p&gt;One might object: "why, then, are &lt;a href="https://www.kommersant.ru/doc/5240226"&gt;those oil and gas oligarchs publicly denounce the war&lt;/a&gt;?" Well, that is one of the more straightforward questions: they are simply preparing an exit strategy for themselves. This is precisely what happened at the Nuremberg tribunal: &lt;a href="https://youtu.be/oyJTv_qLqsI"&gt;German industrialists managed to exit unscathed by pretending to be hostages of the Nazi regime while actually being its beneficiaries&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of course, fuel is not the only reason for this conflict. The annexation of Crimea can also be explained by the strategic importance of Sevastopol (being the only warm-water port of the Russian navy in Europe); and the current war was justified by many with fears of NATO expansion. But let's ask ourselves the question: why does the Russian military even need these strategic footholds? To defend &lt;em&gt;what,&lt;/em&gt; exactly? Certainly not the Russian people, who have been ravaged by COVID-19 for two years now with very little concern from the government. No, the reason a capitalist country needs a military in the first place is to defend the interests of its capital. And which capital has interests important enough to justify an all-out war? &lt;em&gt;Only the carbon capital.&lt;/em&gt; &lt;a href="http://energy-cg.com/UkraineAtRisk.html"&gt;This is why the fight for fossil fuels is the &lt;em&gt;axial&lt;/em&gt; reason behind the war&lt;/a&gt;, meaning that all other causes are merely strung on it.&lt;/p&gt;</content><category term="Пост"></category></entry><entry><title>Let me to the moon, Mom!</title><link href="https://cyberape.space/en/apollo11.html" rel="alternate"></link><published>2019-07-21T00:00:00+01:00</published><updated>2019-07-21T00:00:00+01:00</updated><author><name>FunBotan</name></author><id>tag:cyberape.space,2019-07-21:/en/apollo11.html</id><summary type="html">&lt;p&gt;The 50th anniversary of the moon landing is an excellent opportunity to take a fresh look at our past and future in space.&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;That's one small step for [a] man, one giant leap for mankind.&lt;br&gt;
— Neil Armstrong, 21.07.1969&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This phrase was uttered precisely 50 years ago. Many consider it the most important phrase in history (or maybe the next most important one after «Поехали!»). Many people recognize it even without speaking English. Entire scientific articles have been written about whether it actually contained the indefinite article [a]. And there are serious reasons for all this.&lt;/p&gt;
&lt;p&gt;Despite its militant beginnings in the form of nuclear ICBMs, space exploration always seemed to be the purest, most selfless, and most inspiring vector of technological development. There is no Chornobyl or Facebook in space for critics to point their fingers at as examples of how things can go wrong. People can die in space, sure, but only the people who voluntarily signed up for it, not random, unsuspecting civilians who won’t know what happened until it’s too late. It is difficult to even imagine how that could happen. I can’t remember a single work of science fiction where space exploration &lt;em&gt;itself&lt;/em&gt; would lead humanity to disasters without involving aliens, anomalies, and other external forces. Is that even possible?&lt;/p&gt;
&lt;p&gt;Surely, someone asked similar questions regarding the Internet in the 90s. Can access to all the knowledge in the world &lt;em&gt;narrow&lt;/em&gt; a person’s horizons? Can the ability to communicate with anyone, anywhere, give rise to intolerance? Now we know the paradoxical answer. Social networks alone have probably led to more deaths and disabilities than Chornobyl through acquired mental illnesses and suicides.&lt;/p&gt;
&lt;p&gt;Optimists tend to only imagine the desirable results of applying new technologies rather than the realistic ones, to ignore the &lt;em&gt;achievability&lt;/em&gt; of the desired result in favor of its &lt;em&gt;possibility&lt;/em&gt;. You can draw an infinite number of physically possible future scenarios, but only those from which you can draw a continuous path to the present can be realized. Moreover, as a general rule, the path of least resistance always leads to dystopia.&lt;/p&gt;
&lt;p&gt;For example, it was naive to think that if you give people the Internet, they will start using it for self-education. Some may do, but most will follow the path of least resistance and simply solve their everyday tasks using the Internet: watch the news, order food, and search for partners. Demand creates supply, the industry is left to the whims of the market, and the market will find a way to create a dystopia.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/apollo11/stonks.jpg"&gt;&lt;/p&gt;
&lt;p&gt;The first decades of space exploration were so positive precisely because they &lt;em&gt;didn’t&lt;/em&gt; take the path of least resistance. When Korolev persuaded Khrushchev to start a space program; when Kennedy said, “We &lt;em&gt;choose&lt;/em&gt; to go to the Moon,” they actively steered history, taking it away from the path of least resistance with the sheer power of free will. But they could only maintain the new course for so long.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/apollo11/kennedy.jpg"&gt;&lt;/p&gt;
&lt;p&gt;One could, of course, argue that Elon Musk also made a free choice when creating SpaceX and that he is now at the helm. But, firstly, I doubt that his choice was genuinely free. Secondly, behind Khrushchev and Kennedy stood the People. Behind private space corporations stands only the money. This means that they will inevitably follow the path that allows them to earn as much money as possible: the path of least resistance.&lt;/p&gt;
&lt;p&gt;It’s just that until recently, no one imagined this path leading into space. And the dreamers, who have been waiting for the continuation of the space epic for 50 years, are too intoxicated by success to notice the catch. They expect a logical continuation of the space race of the 20th century, and so far, corporations &lt;a href="https://dearmoon.earth/"&gt;have successfully masqueraded&lt;/a&gt; under this expectation. Awareness of reality will come too late, having gone through all the stages of accepting the inevitable. The ship of history will already be caught up in a powerful current, and it will become impossible to steer out of it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A scientific colleague tells me about a recent trip to the New Guinea highlands where she visited a stone age culture hardly contacted by Western civilization. They were ignorant of wristwatches, soft drinks, and frozen food. But they knew about Apollo 11. They knew that humans had walked on the Moon. They knew the names of Armstrong and Aldrin and Collins. They wanted to know who was visiting the Moon these days.
— Carl Sagan&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Life works so that its worst moments are always ahead, regardless of our actions; however, nothing prevents the best moments from also being there: you just need to make an effort. I argue that the same can be said about the life of civilization as a whole.&lt;/p&gt;
&lt;p&gt;Strongly paraphrasing Tsiolkovsky, we can say that the planet is a parental home of civilization, in which much is given for free but in which we will never be truly free. You can maintain good relationships with your family for a long time, achieve financial independence, and even support your parents with your own income, but sooner or later, you have to leave the home.&lt;/p&gt;
&lt;p&gt;As a civilization, we have already completely ruined our relationship with our parents, and now it is only a matter of time before they force us out of the door. We can move (colonization of space), or we can correct our mistakes and try to restore the relationship (for example, by creating an artificial climate control system in space), but in both cases, we need the skills to live independently (autonomous spaceships).&lt;/p&gt;
&lt;p&gt;Yes, life in space will not be anything like the rosy fantasies of Star Trek. Many dark pages of history are yet to be written. Many nightmares beyond comprehension are closely watching us from the interstellar void, waiting for a chance to take a bite. And realizing this is an essential step on the path to real adulthood. But this is not a reason to hate space or be offended by Elon Musk. Like &lt;a href="https://www.atomicarchive.com/resources/documents/beginnings/einstein.html"&gt;Einstein in 1939&lt;/a&gt;, he does what must be done, even if he will regret it in retrospect.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/apollo11/darkside.png"&gt;&lt;/p&gt;
&lt;p&gt;But what role does Apollo 11 play in this whole analogy? The first cautious step into the adult world, accompanied by obviously unrealistic expectations and indescribable pleasure? The answer suggests itself. This is the first teenage love. A successful and happy, albeit unsustainable and short-lived one.&lt;/p&gt;
&lt;p&gt;Continuing the analogy, we may conclude two things. The first is that we will never have anything like Apollo 11 again. And the second is that something much better may be waiting up ahead.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/apollo11/love.png"&gt;&lt;/p&gt;</content><category term="Праздничный пост"></category></entry><entry><title>The «Black Attractor» Fermi paradox solution</title><link href="https://cyberape.space/en/fermi-paradox.html" rel="alternate"></link><published>2018-04-22T00:00:00+01:00</published><updated>2018-07-02T00:00:00+01:00</updated><author><name>FunBotan</name></author><id>tag:cyberape.space,2018-04-22:/en/fermi-paradox.html</id><summary type="html">&lt;p&gt;A summary of what I believe is the ultimate set of solutions to the paradox.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;This post is deprecated and left here for the sake of history. If you are interested in the topic, I strongly recommend reading &lt;a href="https://cyberape.space/content/pages/black-attractor/paper.pdf"&gt;this much more refined article&lt;/a&gt; instead.&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;The &lt;strong&gt;Fermi paradox&lt;/strong&gt;, named after physicist Enrico Fermi, is the apparent contradiction between the lack of evidence and high probability estimates for the existence of extraterrestrial civilizations. The basic points of the argument, made by physicists Enrico Fermi and Michael H. Hart, are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;There are billions of stars in the galaxy that are similar to the Sun, and many of these stars are billions of years older than the Solar system.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;With high probability, some of these stars have Earth-like planets, and if the Earth is typical, some may have developed intelligent life.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Some of these civilizations may have developed interstellar travel, a step the Earth is investigating now.
Even at the slow pace of currently envisioned interstellar travel, the Milky Way galaxy could be completely traversed in a few million years.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;According to this line of reasoning, the Earth should have already been visited by extraterrestrial aliens. In an informal conversation, Fermi noted no convincing evidence of this, leading him to ask, "Where is everybody?" (&lt;a href="https://en.wikipedia.org/wiki/Fermi_paradox" target="_blank"&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Having studied the vast majority of proposed Fermi paradox solutions, I believe I had found the common misconception that plagues not just them, but multiple seemingly unrelated theories as well. The assumption of rationality.&lt;/p&gt;
&lt;p&gt;But first things first. Why &lt;em&gt;should&lt;/em&gt; we see any signs of alien activity? Because, whatever their logic and motives may be, they should definitely share a common trait: the tendency for growth. It is either included or follows directly from any definition of life. This implies that any life either stops expanding outward at a certain stage, goes extinct, or simply never occurred before. The latter proposition seems extremely improbable given the age of the universe, and the two former ones are more or less the same, since stagnation eventually means running out of energy and dying. The more you think about it, the scarier this idea becomes.&lt;/p&gt;
&lt;p&gt;For now let us assume that our competitors are either dead or never born; that we are the only life within our cosmological horizon; that we are free to make our own choices. &lt;em&gt;Or are we?&lt;/em&gt; Can a civilization really make a deliberate choice, especially one that makes logical sense? If we could, wouldn't we already stop wars, hunger, diseases and climate change? We certainly have the science and resources to do so. So why wouldn't we?&lt;/p&gt;
&lt;p&gt;Because, like any system, society is &lt;em&gt;not&lt;/em&gt; a sum of its members. It is an entity of its own, functioning in accordance with its own rules which couldn't care less about individual humans. Even an ideal totalitarian dictator cannot control the society as a system, let alone the will of the majority. Even though humans are orders of magnitude smarted than ants, &lt;em&gt;humanity&lt;/em&gt; isn't much smarter than an anthill when it comes to making decisions. This is what &lt;a href="https://youtu.be/oo4YAYg68OU" target="_blank"&gt;Noam Chomsky calls "Institutional irrationality"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It actually presents an advantage for science fiction writers: even if it's impossible to imagine a being far smarter than oneself, predicting how those beings will behave as a civilization is very much on the table.&lt;/p&gt;
&lt;p&gt;So, how will &lt;em&gt;humans&lt;/em&gt; behave in the future? To preserve your likely fading attention, I now have to include a chart that explains my vision for the Fermi paradox, that I will then explain step-by-step:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/fermi-paradox/fermi_en.png"&gt;&lt;/p&gt;
&lt;p&gt;We've already concluded that, even if humans aren't the first, other species don't seem to have survived long enough to greet us; so our destiny is up to ourselves. The question then is, "Can we behave rationally?", or "Is there a 'cure' for institutional irrationality?". Both answers lead to fascinating conclusions.&lt;/p&gt;
&lt;p&gt;First, what if we can't? In short term this would mean suffering all the consequences of climate change and possibly a nuclear war, but is that really enough to completely eradicate humanity? I'm not sure about that. Even a small surviving population can quickly rebuild due to information being virtually indestructible at this point. And even if all humans are dead, other species will be happy to take our place. With more than a billion years of mild sunlight remaining, they should have more than enough time to develop intelligence of their own. Hell, they might even evolve space-faring capability through sheer brute force of natural selection! And being wiped out by superintelligent AI only exacerbates the situation, because that AI would have all our faults embedded it its reward function. It would also be life.&lt;/p&gt;
&lt;p&gt;But don't you worry yet, there's another way of destroying ourselves that doesn't rely on sterilizing one particular planet: the way suggested in &lt;a href="https://myanimelist.net/anime/2001/Tengen_Toppa_Gurren_Lagann" target="_blank"&gt;Tengen Toppa Gurren-Lagann&lt;/a&gt;. This must sound like a joke, but bear with me for a while.&lt;/p&gt;
&lt;p&gt;One aspect of institutional irrationality is income inequality. It is not a problem with human civilization in particular, but rather a representation of a more general rule: when tomorrow's state of a variable is directly proportional to today's, its distribution follows &lt;a href="https://en.wikipedia.org/wiki/Pareto_distribution" target="_blank"&gt;Pareto's curve&lt;/a&gt;. There are good reasons to believe that space economy will follow the same rules: the more fuel you have on a spaceship, the further you can go, the more fuel you can mine on-site, etc. What will wealth be measured in? Matter. With advanced enough technology, the kind of matter doesn't make much difference: nearly everything can be used as fuel or construction material. It then naturally follows that everyone would work toward hoarding as much matter as possible and that some will have exponentially more than others. But what happens when you put too much matter in one place, according to relativity?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A black hole happens.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Black holes are the most likely graves for those who came before us, as well as ourselves. A perfect way to make it seem as if we were alone. This isn't even a "Great filter" anymore, but rather a "Great attractor" — the inevitable trap that every civilization has to fall into, sooner or later.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/fermi-paradox/1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;What would be the point of gathering all the matter in such close proximity to enable a collapse? Simply put, protection. The smaller the surface area of an object in space, the easier it is to defend. "Defend from whom?" Again, extrapolation of our present reality yields this answer easily.&lt;/p&gt;
&lt;p&gt;This hypothesis isn't completely untestable, though. Detecting black holes that don't fit our models of galaxy and star formation would be evidence in favor of it. And those black holes &lt;a href="https://physics.aps.org/featured-article-pdf/10.1103/PhysRevLett.116.061102" target="_blank" title="Wow, a link to a legitimate scientific article!"&gt;may actually exist&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Would an entire civilization collapse into that one black hole? Almost certainly not. But those who remain after the catastrophe won't have much resources to rebuild. And when they do rebuild, the same exact catastrophe will repeat. This cycle effectively makes infinite exponential growth — the bedrock of Dyson dilemma, and, consequently, the Fermi paradox — impossible.&lt;/p&gt;
&lt;p&gt;In the process of gathering enough matter we are also likely to devour other inhabited solar systems that haven't yet evolved to our level, the same way a construction crew demolishes anthills before building real estate on their place. The scale of destruction is hard to estimate now, but it might well envelop the entire supercluster. Destroying the entire universe, as suggested by the chart, is theoretically impossible, but it doesn't make much difference. The most obvious counterargument, "But surely an interstellar civilization won't be dumb enough to collapse itself into black holes!", contradicts the assumption we've made by going down this logical branch on the chart above, namely "We can't behave rationally".&lt;/p&gt;
&lt;p&gt;But what if we can?&lt;/p&gt;
&lt;p&gt;Well, even if &lt;em&gt;we&lt;/em&gt; can, &lt;em&gt;others&lt;/em&gt; probably don't. And we cannot sit idly by as some alien species is devouring &lt;em&gt;our&lt;/em&gt; supercluster. The best thing we can do to benefit everyone is to forcefully stagnate their development, trap them in their home solar system before it's too late. At least that seems to be the only alternative to complete eradication of all alien life.&lt;/p&gt;
&lt;p&gt;The Zoo hypothesis and the Matrix now seem much more feasible. Maybe, we aren't alone after all? Maybe, our world isn't really &lt;em&gt;ours&lt;/em&gt;? Actually, that might be the best option of all. In this case, we are alleviated from the privilege of making the hard decisions and hard mistakes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/fermi-paradox/2.jpg"&gt;&lt;/p&gt;</content><category term="Post"></category></entry></feed>