<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Cyber Ape stories</title><link href="https://cyberape.space/en/" rel="alternate"></link><link href="https://cyberape.space/atom" rel="self"></link><id>https://cyberape.space/en/</id><updated>2023-12-12T00:00:00+00:00</updated><entry><title>Embeddings, Aufhebung &amp; Denkökonomie</title><link href="https://cyberape.space/en/embeddings.html" rel="alternate"></link><published>2023-12-12T00:00:00+00:00</published><updated>2023-12-12T00:00:00+00:00</updated><author><name>FunBotan</name></author><id>tag:cyberape.space,2023-12-12:/en/embeddings.html</id><summary type="html">&lt;p&gt;Connecting some dots between machine learning, neurobiology, and the 19th-century German philosophy&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Machine learning perspective&lt;/h2&gt;
&lt;p&gt;Without knowing anything about the nature of colors, we may naively assume that each hue (red, green, blue, yellow, purple, etc.) exists independently of the others. However, having started mixing colors, we quickly (or not so quickly) come to the conclusion that there are only three truly independent colors: red, green, and blue, and all the rest are their &lt;em&gt;linear combinations&lt;/em&gt;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; (mixtures in different proportions).&lt;/p&gt;
&lt;p&gt;Even for those with little knowledge of mathematics, it should not be difficult to imagine colors as three-dimensional vectors (lists of three numbers). But what is the benefit of this representation? Firstly, we obtain a correspondence between the physical process of color mixing and arithmetic operations on vectors. Secondly, this representation is also maximally &lt;em&gt;compressed&lt;/em&gt;; it takes up the minimum possible amount of memory.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="{filename}rgb.jpg"&gt;&lt;/p&gt;
&lt;p&gt;The example of colors is good precisely because we know the answer in advance. But there are many other classes of objects for which we would like to obtain a representation with similar properties, but how to do this is not at all obvious. One such class could be &lt;em&gt;words&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Again, we can start with the assumption that all words are independent of each other; that is, in the linear space of words, each of them corresponds to its own dimension (this approach is called one-hot encoding). But this assumption will quickly be shattered by fairly obvious examples of antonyms, such as “high - low,” “bright - dim,” “help - hinder,” “loud - quiet.” For each pair of antonyms, we can write down an equation of the form “high + low = 0”, “help + hinder = 0”, etc. In this way, we algebraically &lt;em&gt;express&lt;/em&gt; one word through another, which means we can eliminate one of the two dimensions originally allocated to them. Moreover, the right side of these equations needs not be zero. It could also be a non-zero vector: &lt;em&gt;another word&lt;/em&gt;. For example: “damp + cold = dank”, “irony + mockery = sarcasm”, “music + poetry = song”. Moving up a level to four words in one equation, we can begin to illustrate the different kinds of relationships between words. For example, “king - man + woman = queen” is a semantic relationship, and “big + less = small + more” is a syntactic one. These are just the simplest examples; there is no limit to the complexity of such constructs.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="{filename}words.png"&gt;&lt;/p&gt;
&lt;p&gt;The problem is that considering all possible verbal equations for expressing words through each other and determining the relative positions of their corresponding vectors is a task that is far beyond reasonable in terms of labor intensity. Which is why it was solved only with the advent of machine learning. A breakthrough in word vectorization was the simply named &lt;a href="https://arxiv.org/abs/1301.3781"&gt;word2vec algorithm&lt;/a&gt;, published a decade ago. The general public probably remembers it from some meme-worthy examples of verbal equations:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;pig - oink + Santa = HO HO HO&lt;br&gt;
pig - oink + Woody Woodpecker = Yabba dabba doo&lt;br&gt;
pig - oink + Fred Flinstone = wassup&lt;br&gt;
pig - oink + Homer Simpson = D’oh&lt;br&gt;
pig - oink + Donald Trump = YOU’RE FIRED&lt;br&gt;
pig - oink + Einstein = E = mc2&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Along with machine learning, a new word has appeared to describe such vector representations of objects: &lt;strong&gt;embeddings&lt;/strong&gt;, also known as latent vectors, since the linear space they occupy is called &lt;strong&gt;latent space&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The algorithm for generating embeddings turned out to be rather indirect. It consists of training a model, usually a neural network, to &lt;em&gt;guess&lt;/em&gt; information. For example, in the case of words, we can remove one word from a sentence and have the model &lt;em&gt;predict&lt;/em&gt; what should be in its place. Embeddings are generated during the training process as the model’s internal representations of data which it is processing. If this explanation was confusing, then you only have to remember one thing: the connection between embeddings and predictions. We will need this connection soon.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="{filename}translation.png"&gt;&lt;/p&gt;
&lt;p&gt;An interesting property of language is that embeddings of words from different languages will form a very similar structure, and by overlaying the latent spaces of different languages, one can create a dictionary for translation between them &lt;em&gt;without a single example of actual translation&lt;/em&gt;. This property has been known for a long time, albeit in a different formulation, and was used by archaeologists to decipher dead languages long before machine learning. It indicates that embeddings are not arbitrary but are an objective property (or rather, a homomorphic image) of what they are encoding. So, in the limit, different methods for calculating embeddings of the same objects should theoretically converge to similar results.&lt;/p&gt;
&lt;p&gt;With the help of machine learning, we can calculate embeddings for anything, provided that we have a sufficient number of examples illustrating relationships between the objects in question. For example, texts can be used to construct word embeddings, but you can also embed higher-level structures: sentences, paragraphs, entire articles. They will simply require many more examples. Images are a little more complicated, but if you've ever solved a captcha like "select all squares that contain X to prove you're not a robot", you've helped some corporation (most likely Google) create better image embeddings.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="{filename}captcha.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Embedding technology is also a pillar of all breakthroughs in the field of artificial intelligence in recent years, which is not surprising: embeddings, in essence, are a portal between the real world of people and the digital world of machines. ChatGPT and other generative neural networks like Stable diffusion and Midjourney rely on them.&lt;/p&gt;
&lt;p&gt;But what are embeddings at a fundamental level? By formal definition, they are just vectors whose geometric distance is proportional to the similarity of the objects they represent (an isometric homomorphism, if you will). Essentially, computing embeddings is the task of &lt;em&gt;classifying&lt;/em&gt; objects and determining their degree of relatedness, whatever that means in each specific case.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="{filename}sentences.png"&gt;&lt;/p&gt;
&lt;p&gt;This property of correspondence between geometrical distance in latent space and similarity of embedded objects can be leveraged to perform similarity search. First, you build a database of embeddings (called a vector database) as a key-value storage, with vectors being keys and original objects being values. Then, you can run any new object through the same model to obtain its embedding. Finally, you do a K-nearest-neighbors search on that embedding in the database and return the values corresponding to found keys. This is roughly how image search, facial recognition, and recommendation algorithms work. Even most text search engines already use embeddings to search not only for literal matches with the search query but also for texts that are similar in meaning but phrased differently. Such search is called &lt;em&gt;semantic&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="{filename}vdb.png"&gt;&lt;/p&gt;
&lt;p&gt;But, as I briefly mentioned at the beginning, a side effect of computing embeddings is the compression of information&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;. And there is some reason to believe that this is not just a side effect but an &lt;em&gt;equivalent definition&lt;/em&gt; of embeddings. This reason is an incredibly interesting &lt;a href="https://aclanthology.org/2023.findings-acl.426/"&gt;article&lt;/a&gt;, which proposes a way to measure distance between texts using compression (based on the notion of &lt;a href="https://brilliant.org/wiki/kolmogorov-complexity/"&gt;Kolmogorov complexity&lt;/a&gt;), thereby allowing the use of compressed texts as quasi-embeddings. It then compares embeddings produced by the most powerful language models with a conventional Gzip archiver in the text classification task. Paradoxically, in many tests (especially on small samples and outside the training distribution), Gzip's performance came close to much more complex language models.&lt;/p&gt;
&lt;p&gt;If that made no sense to you, then here is the conclusion in simpler words. Classifying objects requires identifying their common features, but if we have found such features, then we no longer need to remember them for each object separately; it is enough to have one record for all objects of the same class. Conversely, the task of information compression requires a reduction of repeating sequences, which turn out to be common properties of objects. In other words, both tasks come down to &lt;em&gt;generalization&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;But notice that neither machine learning nor even embeddings themselves appear in the previous paragraph. This is because it uncovers a much more general principle that applies, among other things, to the human brain. Evidence of this can be found in research from the field of mind reading: this year alone, two sci-fi-level results were obtained there.&lt;/p&gt;
&lt;p&gt;The first is the &lt;a href="https://www.nature.com/articles/s41593-023-01304-9"&gt;semantic reconstruction of language&lt;/a&gt;: decoding heard, read, and even imaginary (internal) speech from brain scans. Remarkably, the developed system does not reproduce words exactly but in a slightly different formulation that preserves the general meaning, hence the “semantic” qualifier. This means that it reconstructs &lt;em&gt;the thoughts&lt;/em&gt; themselves and not, for example, the motor signals that the brain involuntarily sends to the tongue and larynx, even when it is not speaking out loud. But most interestingly, if the same system is used on a person who is watching a silent film, the result of decoding their thoughts will be a text description of the scenes of this film!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ai.meta.com/blog/brain-ai-image-decoding-meg-magnetoencephalography/"&gt;The second result&lt;/a&gt; is a similar system but for the reconstruction of images, visible or imaginary. Its properties are the same: the images do not match exactly, but they are similar in a rather curious way, reflecting what details the person is paying attention to.&lt;/p&gt;
&lt;p&gt;Both systems share a very similar architecture and contain two key elements:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generative neural network. Semantic language reconstruction uses GPT-1, and image reconstruction uses a diffusion model from the same class as Stable diffusion and Midjourney.&lt;/li&gt;
&lt;li&gt;A model of the subject’s brain, implemented as an artificial neural network that, based on data (text or picture), predicts what signals the brain that thinks about this data will produce. I was amazed by the fact that this is already possible: in theory, modeling the human brain should not be achievable with the current level of technology. However, the models exist, and they work. Even if this is just a rough approximation at the moment, the very fact that such an approximation is possible and useful makes a big difference in estimating the complexity of this problem. Fortunately, to obtain results, the model must be trained individually on each subject, which is impossible without their cooperation, so it’s yet too early to worry about the adoption of mind reading by states and corporations for nefarious purposes. &lt;em&gt;Yet.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The system works as follows. First, the generative neural network creates many different variations of text or images. These options are fed to the neural network that models the brain, and it generates corresponding signals. They are compared with real brain scans of the subject, and the most similar ones are selected. The data that generated these signals arrive at the output of the system as decoded results, but at the same time are transmitted back to the generative model, which generates suitable continuations to repeat the process.&lt;/p&gt;
&lt;p&gt;All this is strikingly reminiscent of the semantic search mechanism described above. If we treat brain states as analogs of embeddings, then the process of mind decoding is just a similarity search in the space of these embeddings. Indeed, earlier studies independently confirmed that &lt;a href="https://www.nature.com/articles/nature21692"&gt;the brain also uses the concept of latent space&lt;/a&gt;, and &lt;a href="https://proceedings.neurips.cc/paper/2018/file/99064ba6631e279d4a74622df99657d6-Paper.pdf"&gt;the process of memory consolidation in the hippocampus is strikingly similar to the computation of embeddings&lt;/a&gt;. Particularly amazing is a &lt;a href="https://arxiv.org/pdf/2112.04035.pdf"&gt;paper showing equivalence&lt;/a&gt; between the hippocampus model and transformers, a class of artificial neural networks that underlie recent breakthroughs in natural language processing (that’s what T in GPT stands for) and which were developed without any prior knowledge of neurobiology. So, science once again converged to a solution that nature had already invented&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;. But this raises another question: what problem was &lt;em&gt;nature&lt;/em&gt; solving?&lt;/p&gt;
&lt;h2&gt;Neurobiological perspective&lt;/h2&gt;
&lt;p&gt;On the one hand, the adaptive value of the human brain cannot be overestimated (says a human brain, ha-ha), which means that its development should have been very strongly encouraged by natural selection. This is supported by the relatively rapid evolution of the human brain. On the other hand, biophysics imposes strict constraints on the parameters of the brain. These are, firstly, physical dimensions, limited by the constraint of having to be born. Secondly, the human brain already consumes a fifth of the body’s total energy, and energy in nature is a strictly limited resource, so there was no opportunity to freely increase its consumption until quite recently, by evolutionary standards, with the emergence of agriculture. Thus, we have a very acute contradiction between the need to increase the power of the brain and the limitations on the parameters by which this could be achieved. It then follows that &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5651807/"&gt;the evolution of the brain should have gone in the direction of increasing &lt;em&gt;efficiency&lt;/em&gt;&lt;/a&gt;. And indeed, it seems that &lt;a href="https://www.lesswrong.com/posts/xwBuoE9p8GE7RAuhd/brain-efficiency-much-more-than-you-wanted-to-know"&gt;it is already about as efficient as it can theoretically be&lt;/a&gt;. Many other human adaptations &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9197885/"&gt;that increase energy efficiency at the expense of brute force&lt;/a&gt; hint at the same direction.&lt;/p&gt;
&lt;p&gt;But how is this efficiency achieved? For the answer, we again have to turn to machine learning, which &lt;a href="https://arxiv.org/abs/1605.08104"&gt;found&lt;/a&gt; that if you constrain the model in the energy budget, it automatically produces a predictive coding mechanism: the same one that produces embeddings! Moreover, transferring this result from artificial neural networks to biological ones is not a leap of faith: we already know for sure that predictive coding mechanisms arise in almost any well-optimized part of the brain.&lt;/p&gt;
&lt;p&gt;Since humans spend most of their time communicating with others (or at least did so until they invented the damned Internet), optimizing social interaction has been a high priority for evolution. The result of this optimization was, on the one hand, a &lt;a href="https://pubmed.ncbi.nlm.nih.gov/12921766/"&gt;highly specialized language cortex&lt;/a&gt;, which &lt;a href="https://www.nature.com/articles/s41562-022-01516-2"&gt;constantly tries to predict what it will hear&lt;/a&gt;, and on the other, mirror neurons, which completely model the mental state of other people (and, with proper development, not only people), and therefore they inevitably operate with compressed representations, since no system can completely model itself.&lt;/p&gt;
&lt;p&gt;“What I cannot create, I do not understand,” said Richard Feynman. If we think this way, it’s hard not to come to the conclusion that the creation of artificial intelligence is our most successful attempt to understand our own.&lt;/p&gt;
&lt;p&gt;From a theoretical point of view, all this fits perfectly into the system of general &lt;a href="https://en.wikipedia.org/wiki/Good_regulator"&gt;theorems&lt;/a&gt; formulated for all systems, including brains, within the framework of cybernetics. &lt;a href="http://www.hutter1.net/ai/aixigentle.htm"&gt;One of these theorems&lt;/a&gt; states that if we consider the subject and the world with which they interact as computers exchanging information, then making optimal decisions for the subject, which is equivalent to predicting the consequences of available actions, is reducible to the maximum compression of information about the world. Of course, it would be premature to transfer this theorem to the real world since it is based on a rather shaky assumption of universal computability. But it would be equally unwise to ignore its conclusion.&lt;/p&gt;
&lt;p&gt;And now, it's finally time to put everything together. Efficiency necessitates prediction, prediction necessitates generalization, generalization is equivalent to compression... And what is compression? It is the &lt;em&gt;efficiency&lt;/em&gt;&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt; of storing information! The loop is closed, which means that all these processes are equivalent to each other at a fundamental level!&lt;/p&gt;
&lt;h2&gt;Philosophical perspective&lt;/h2&gt;
&lt;p&gt;The conclusion derived above is, of course, not that new. Similar ideas have been put forward in many forms, starting perhaps from an Austrian philosopher &lt;a href="https://www.leopoldina.org/fileadmin/redaktion/Mitglieder/CV_Ernst_Mach_D.pdf"&gt;Ernst Mach&lt;/a&gt; and &lt;a href="https://plato.stanford.edu/entries/ernst-mach/#Sci"&gt;his scientific framework of &lt;em&gt;Denkökonomie&lt;/em&gt;&lt;/a&gt;, which literally translates to “economy of thought”, “economy” meaning savings or efficiency. At its core, this framework demands the simplest possible (most economical) explanation of observed facts in science; it's essentially a beefed-up version of Occam's Razor, which Mach also derived from biological necessity. Today, however, Denkökonomie is remembered more through its criticisms rather than the primary source, and for a good reason: Mach eventually reasoned himself into solipsism by an overly extreme application of his own principle. And there are good reasons to understand how this happened.&lt;/p&gt;
&lt;p&gt;If we accept that (1) Denkökonomie is a &lt;em&gt;sufficient&lt;/em&gt; criterion of truth and (2) the brain always strives for the most economical explanation of observed facts, then it follows that all people, as they gain experience, should converge on identical ideas about the world. But empirically, this obviously does not happen. This contradiction can be explained in two ways. The way that Mach chose was to deny the materiality of the world. Indeed, if each observer analyzes their own world, then there is no basis for consistency between their models of those worlds. But a much more economical way to explain the same contradiction is to abandon one of Mach's postulates. Since postulate 2 is now backed by science (as explained above), the problem is obviously in postulate 1. That is, Denkökonomie is not a sufficient but a necessary criterion of truth. Put simply, this means the truth cannot be found by following simplicity alone (string theory and supersymmetry empirically demonstrated this), but somehow, the truth always turns out to be simple.&lt;/p&gt;
&lt;p&gt;But what do we mean by this complexity/economy quantitatively? One answer is explanatory power, which is expressed as a ratio of the number of observations a theory explains divided by the number of assumptions that it relies on and which are unprovable within it. This is usually enough to compare two theories within the same subject domain. In the context of statistical models, the number of assumptions can be replaced with the number of trainable parameters. But it is possible to generalize even further.&lt;/p&gt;
&lt;p&gt;Recall the concept of &lt;a href="https://brilliant.org/wiki/kolmogorov-complexity/"&gt;Kolmogorov complexity&lt;/a&gt; mentioned earlier. Based on it, a theoretical measure of complexity for scientific theories was suggested by Ray Solomonoff as part of his &lt;a href="https://www.lesswrong.com/posts/Kyc5dFDzBg4WccrbK/an-intuitive-explanation-of-solomonoff-induction#Solomonoff_s_Lightsaber"&gt;theory of inductive inference&lt;/a&gt;. This is, in essence, a mathematical formalism for Mach's philosophical framework. It, in turn, was the basis for &lt;a href="https://www.lesswrong.com/posts/DFdSD3iKYwFS29iQs/intuitive-explanation-of-aixi"&gt;AIXI&lt;/a&gt;: an algorithm that is supposedly capable of discovering the most economic theories automatically; in other words, an AGI. The only issue is that none of these things are computable, which is why they were never used in practice. Some, however, try to &lt;a href="https://arxiv.org/abs/1007.2049"&gt;approximate AIXI&lt;/a&gt;, and this avenue of research probably deserves more attention.&lt;/p&gt;
&lt;p&gt;It is easy to see that scientific progress almost always goes in the direction of more economical theories, at least when considered &lt;em&gt;on a sufficiently long time scale&lt;/em&gt;. For example, when radioactivity was first described, it did not fit into existing physical theories at all, and initially, it had to be considered as a completely independent phenomenon, which, of course, is not economical in the short term. But new theories soon emerged, combining old physics with new phenomena into a single and more economical system, and at the same time explaining things that previously seemed inexplicable: why are stars burning, and where atoms come from. Mach himself likely developed his framework by trying to formalize this very observation.&lt;/p&gt;
&lt;p&gt;But there are also situations where Denkökonomie &lt;em&gt;can&lt;/em&gt; be used as a criterion of truth, namely, all else being equal. For example, if we put ourselves in the shoes of people who do not yet know about Newton's theory of universal gravitation, then how should we choose between the geocentric and heliocentric cosmological models? Both give fairly accurate predictions, so it is impossible to reject one of them by experiment alone. What is the difference between them? The heliocentric model uses a fixed and small number of parameters to describe orbits, while the geocentric model, in order to achieve the same accuracy, requires winding epicycles onto epicycles, thereby generating many more parameters. Later, Joseph Fourier invented one of the most powerful tools of mathematics: the Fourier transform, which allows one to describe &lt;em&gt;any&lt;/em&gt; trajectory or signal in a similar way. Hence, the geocentric model is bad not because it is incorrect but because it does not actually contain information about the motion of the planets: all this information is stored in its parameters. The heliocentric model &lt;em&gt;compresses&lt;/em&gt; this information, &lt;em&gt;saving&lt;/em&gt; parameters, and this is what makes it preferable. In other words, the heliocentric model has greater explanatory power.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="{filename}centrism.png"&gt;&lt;/p&gt;
&lt;p&gt;While we should strive to use “Copernican modeling” wherever possible, there are problems where this approach fails, and we are forced to resort to “Ptolemaic modeling.” Statistics and machine learning are essentially sciences that study how to do it properly.&lt;/p&gt;
&lt;p&gt;The price for using over-parametrized modeling is usually the model's inability to &lt;em&gt;generalize&lt;/em&gt;. In order to at least somewhat regain it, regularization and dimensionality reduction methods were invented. They can be described as artificially limiting the complexity of the model in terms of the number of parameters or their values: in essence, forcing the model to be more &lt;em&gt;economical&lt;/em&gt;. These methods come dangerously close to using Denkökonomie as a &lt;em&gt;sufficient&lt;/em&gt; criterion of truth, but practice shows that they work, and it is practice that is the ultimate criterion of truth.&lt;/p&gt;
&lt;p&gt;But let us return to the contradiction in Mach's philosophy. Even having rejected Denkökonomie as a sufficient criterion of truth, we are still left with the question: why do different people come to completely different ideas about the world if its economical (compressed) representation, which the brain seeks to find, must be objective and independent of the observer? To answer this, we will have to turn to another branch of philosophy: dialectics.&lt;/p&gt;
&lt;p&gt;What we need from dialectics specifically is the concept of “&lt;a href="https://en.wikipedia.org/wiki/Aufheben"&gt;&lt;em&gt;Aufhebung&lt;/em&gt;&lt;/a&gt;,” which I will translate as “overcoming,” although no perfect translation to English exists. A classic example that demonstrates this concept is found in the relationship of the general theory of relativity and quantum mechanics with classical mechanics. These more advanced theories extend beyond classical mechanics, yet they also preserve it as a special case in the limit: when the speed of light approaches infinity and the Planck constant approaches zero, respectively. Technically, we can say that these theories are &lt;em&gt;contradictory&lt;/em&gt; because, &lt;em&gt;empirically,&lt;/em&gt; the speed of light is not infinite, and Planck's constant is not zero. But the important thing is that more advanced theories can usually simulate less advanced ones through similar thought experiments.&lt;/p&gt;
&lt;p&gt;The procedure of dialectical overcoming is invaluable in theoretical disputes, where the opponent will always present facts that do not fit into your theory. If you cannot use it, you will eventually find yourself sandwiched between two losing options: challenging the facts and removing the facts from the scope of your theory. But the ability to overcome such contradictions not only allows you not to lose an argument but also turns the dispute into a full-fledged research activity that can potentially lead to new discoveries. In such a dispute, truth can really be born.&lt;/p&gt;
&lt;p&gt;However, the easiest way to trace the process of dialectical overcoming is not in discussions between different people but in the process of development of a single person: oneself. Each of us, in the depths of our closets or hard drives, has some notes from ancient times, looking at which we can &lt;s&gt;die of cringe&lt;/s&gt; understand how our worldview developed. And the basic law of this development is the preservation of previous versions of ourselves that we overcame. We never throw away all previous experience to start from scratch. Even when radically changing our views, in the new ones, we retain an imprint of the old ones, which strengthens them. For example, it allows us to argue for the new worldview much more competently compared to those for whom it is the starting point. I also believe that somewhere here lies the answer to the &lt;a href="https://www.cs.uic.edu/~liub/lifelong-learning/continual-learning.pdf"&gt;problem of continual learning&lt;/a&gt;, but extracting it will take some more work.&lt;/p&gt;
&lt;p&gt;For the same reason, not a single generally accepted theory in modern positive science can be &lt;em&gt;refuted&lt;/em&gt;. The only way to advance further in knowledge is to &lt;em&gt;overcome&lt;/em&gt; the old theory, that is, to find a more general theory, a special case of which will be the old one. But since generalization, as we found out above, is equivalent to compression, it turns out that &lt;em&gt;the result of dialectical overcoming should be more economical&lt;/em&gt;. And since dialectical overcoming is also a process of removing contradictions, the converse proposition can be formulated: &lt;em&gt;the more economical our theories are, the fewer contradictions there are between them&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The same logic explains why persuading people generally doesn't work. It is impossible to produce an “embedding” that can natively integrate into another person's “latent space” without access to their subjective experience, which is inaccessible to us by definition. Only I myself can convince myself of something, either in order to resolve the contradiction in my current model of reality or &lt;a href="http://publicsociology.tilda.ws/ukreng"&gt;under the influence of material factors&lt;/a&gt;. Socrates’ “maeutics” is based on the first option: it consists of identifying contradictions in the interlocutor’s worldview and making them obvious. Sometimes, this leads to the interlocutor reflecting and changing their opinion in order to resolve the contradiction. However, it is impossible to guarantee persuasion, let alone in a specific direction. Socrates was fine with that: in his gnoseology, each person already contained true knowledge about the world a priori, and all he had to do was to extract it. But that view leads to the same dead end in which Mach later ended up.&lt;/p&gt;
&lt;p&gt;Another significant drawback to this architecture is that it’s &lt;em&gt;monolithic&lt;/em&gt;, meaning that it’s impossible to transfer a part of knowledge from one model to another. Returning to the example of embeddings, we can see a manifestation of this problem in that the embeddings themselves are useless without the model that generated them. For the same reason, it is impossible to simply “download” the knowledge accumulated by humanity into the brain of an individual person. Each brain is a new model, and each must independently build its “latent space” from scratch. For this, it must conceptually go through the path that its predecessors already took (this is indirectly confirmed by the above studies on mind reading, where a model must be fitted to each subject). The development of a person repeats in miniature the development of the entire civilization in which they happened to be born. This, by the way, imposes an unpleasant limitation on science itself: sooner or later, the time required to retrace the path of humanity, even in its most compressed form, will exceed life expectancy, and new generations simply will not have enough time to create something original; therefore, artificial life extension or other ways of overcoming this limitation (e.g., hiveminds) will become a necessary condition of further progress. But today may be too early to worry about it.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Actually, colors form not a linear space but a symmetry group SU(3). However, in the interval [0;1], it behaves in the same way as a linear space, and it is in this interval that we usually work with colors. Just be careful with subtraction.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Here, I deliberately omit the rather important difference between lossless and lossy compression. Most embedding models are not designed for restoring the original object using the embedding itself, i.e., if they implement compression, it is a very lossy one. But this clarification becomes unnecessary when we move on to the discussion of human memory, in which these two types of information storage differ more quantitatively than qualitatively.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;You can also recall the story of convolutional neural networks (CNN), which replicate the structure of the mammalian visual cortex. But in this case, people &lt;a href="https://doi.org/10.1162/jocn_a_01544"&gt;deliberately “copied” an architecture from nature&lt;/a&gt;, which is much less interesting than the independent (convergent) emergence of the same architecture in nature and technology.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;Here I can be accused of substituting the thesis: at the beginning, it was about minimizing thinking, and at the end about minimizing memory. But these things are quite related. Once an economical (compressed) model has been created, cognitive operations with it also simplify, becoming more economical.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Пост"></category></entry><entry><title>Nothing personal, just business</title><link href="https://cyberape.space/en/war.html" rel="alternate"></link><published>2022-03-13T00:00:00+00:00</published><updated>2022-03-13T00:00:00+00:00</updated><author><name>FunBotan</name></author><id>tag:cyberape.space,2022-03-13:/en/war.html</id><summary type="html">&lt;p&gt;Looking for the reasons behind the unreasonable&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;People always have been the foolish victims of deception and self-deception in politics, and they always will be, until they have learned to seek out the interests of some class or other behind all moral, religious, political and social phrases, declarations and promises.&lt;/p&gt;
&lt;p&gt;— Vladimir Lenin&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Easy as it is to apply this great principle in hindsight, to events long past and well studied. It's another matter entirely to do so in a state of shock and awe that we have all found ourselves in the morning of February 24, 2022.&lt;/p&gt;
&lt;p&gt;At first glance, it may seem that the invasion of Ukraine by Russia cannot possibly have a rational, materialistic justification. Too high are the costs Russia will have to pay even in the case of total victory (which itself is becoming less and less plausible by the day), let alone in the case of defeat. What could possibly motivate the Russian ruling class to go for broke to this extent? Let me explain.&lt;/p&gt;
&lt;h1&gt;Who is to blame?&lt;/h1&gt;
&lt;p&gt;It's no secret that the &lt;a href="https://atlas.cid.harvard.edu/explore?country=186&amp;amp;product=undefined&amp;amp;year=2019&amp;amp;productClass=HS&amp;amp;target=Product&amp;amp;partner=undefined&amp;amp;startYear=undefined"&gt;primary exports of Russia are oil and gas&lt;/a&gt;. Revenue from their sale comprises half of the state budget and 30% of GDP. The Russian regime has put all of its bets on the carbon horse, &lt;a href="https://www.rt.com/business/541415-russia-oil-reserves-decline/"&gt;and now that horse is getting tired&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To understand how Ukraine comes into the picture, we need to go back to 2012, when &lt;a href="https://www.iene.gr/6thSEEED/articlefiles/sessionIII/Hutta.pdf"&gt;huge offshore gas deposits were discovered in its territorial waters around Crimea&lt;/a&gt;. Around the same time, fracking was developed in the USA, which opened access to &lt;a href="http://shalegas.in.ua/en/shale-gas-resources-in-ukraine/"&gt;shale gas deposits under Donbas and Transnistria&lt;/a&gt;. Can it be just a coincidence that the same regions have the highest levels of ethnic tensions and separatist sentiments?&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/war/basis.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Ukraine, however, lacked the domestic capital and technology to extract all these resources. This naturally pushed the Ukrainian capital into the embrace of the American one: &lt;a href="https://www.offshore-technology.com/uncategorised/newsexxon-consortium-ukraine-skifska-oil-gas-field/"&gt;Yanukoviche's government began issuing drilling permits to such companies as Shell and Exxon&lt;/a&gt;. Had the Russian capital left the situation to be handled by the "invisible hand of the market," Ukraine might have become the second-largest exporter of gas in Europe in a few years, or maybe even push Russia out of the market: Western Europe would have preferred to buy gas from convenient Ukraine rather than wild and unpredictable Russia. And from there, it wouldn't be a stretch to imagine Ukraine in the EU or even NATO.&lt;/p&gt;
&lt;p&gt;Had Yanukovich and his clique retained their power, they would broker a deal with Russian capital. But then 2014 happened: American capital had openly entered the game, raising the stakes tremendously. Russia replied by &lt;a href="https://euromaidanpress.com/2018/10/10/black-sea-gas-deposits-an-overlooked-reason-for-russias-occupation-of-crimea/"&gt;annexing Crimea&lt;/a&gt; and &lt;a href="https://www.bbc.com/ukrainian/ukraine_in_russian/2015/12/151216_ru_s_ukraine_russia_sea"&gt;immediately proceeding with offshore drilling in its waters&lt;/a&gt;. As for the shale deposits, &lt;a href="https://www.euractiv.com/section/energy/opinion/russia-s-silent-shale-gas-victory-in-ukraine/"&gt;their development was effectively stalled by civil war&lt;/a&gt;, which Russia was satisfied with at the time: it didn't have the fracking technology to begin with.&lt;/p&gt;
&lt;p&gt;Just to relieve any doubts, in 2014, &lt;a href="https://tass.ru/mezhdunarodnaya-panorama/6964280"&gt;Joe Biden had placed his son on the board of directors of the largest Ukrainian oil and gas holding&lt;/a&gt;. Also, &lt;a href="https://vesma.today/news/post/36142-ukrainskiy-milliarder"&gt;one Ukrainian oil oligarch has committed suicide shortly after the war started&lt;/a&gt;, which might not prove anything by itself, but fits quite nicely into the bigger picture.&lt;/p&gt;
&lt;p&gt;Why were the Russian elites waiting for eight years to continue the war? That's not entirely clear at the moment. One plausible reason is the unprecedented growth of gas prices in Europe, which made imposing sanctions harder for the European economy than ever. Another possibility is the dire need for fresh water in Crimea: not coincidentally, &lt;a href="https://youtu.be/Gi6EYIS7isk"&gt;one of the first targets of the Russian military was the dam blocking the North-Crimean canal&lt;/a&gt;. The peninsula wouldn't survive another 2020-level drought. Ironically, the reason behind the severity of that drought was climate change, which is a direct effect of the very industry that fuels Russian aggression.&lt;/p&gt;
&lt;p&gt;Beside that, in 2005, 80% of Russian gas exports to Europe were pumped through pipelines lying in Ukraine, which were only supposed to be decommissioned by 2024. Despite the war, &lt;a href="https://ria.ru/20220301/gaz-1775733192.html"&gt;these pipelines are still working&lt;/a&gt;, and &lt;a href="https://www.gazprom.ru/investors/disclosure/actual-supplies/"&gt;their utilization is only growing&lt;/a&gt; along with gas prices. Apparently, the Russian capital has deemed Nord Stream 2 an acceptable sacrifice for regaining control over the older pipes that Ukrainians will no longer demand a transit fee to use. And even if a stray shell bursts a pipe here or there, it will only further raise gas prices, making the whole affair even more profitable.&lt;/p&gt;
&lt;p&gt;One might object: "why, then, are &lt;a href="https://www.kommersant.ru/doc/5240226"&gt;those oil and gas oligarchs publicly denounce the war&lt;/a&gt;?" Well, that is one of the more straightforward questions: they are simply preparing an exit strategy for themselves. This is precisely what happened at the Nuremberg tribunal: &lt;a href="https://youtu.be/oyJTv_qLqsI"&gt;German industrialists managed to exit unscathed by pretending to be hostages of the Nazi regime while actually being its beneficiaries&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of course, fuel is not the only reason for this conflict. The annexation of Crimea can also be explained by the strategic importance of Sevastopol (being the only warm-water port of the Russian navy in Europe); and the current war was justified by many with fears of NATO expansion. But let's ask ourselves the question: why does the Russian military even need these strategic footholds? To defend &lt;em&gt;what,&lt;/em&gt; exactly? Certainly not the Russian people, who have been ravaged by COVID-19 for two years now with very little concern from the government. No, the reason a capitalist country needs a military in the first place is to defend the interests of its capital. And which capital has interests important enough to justify an all-out war? &lt;em&gt;Only the carbon capital.&lt;/em&gt; &lt;a href="http://energy-cg.com/UkraineAtRisk.html"&gt;This is why the fight for fossil fuels is the &lt;em&gt;axial&lt;/em&gt; reason behind the war&lt;/a&gt;, meaning that all other causes are merely strung on it.&lt;/p&gt;</content><category term="Пост"></category></entry><entry><title>The «Black Attractor» Fermi paradox solution</title><link href="https://cyberape.space/en/fermi-paradox.html" rel="alternate"></link><published>2018-04-22T00:00:00+01:00</published><updated>2018-07-02T00:00:00+01:00</updated><author><name>FunBotan</name></author><id>tag:cyberape.space,2018-04-22:/en/fermi-paradox.html</id><summary type="html">&lt;p&gt;A summary of what I believe is the ultimate set of solutions to the paradox.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;This post is deprecated and left here for the sake of history. If you are interested in the topic, I strongly recommend reading &lt;a href="https://cyberape.space/content/pages/black-attractor/paper.pdf"&gt;this much more refined article&lt;/a&gt; instead.&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;The &lt;strong&gt;Fermi paradox&lt;/strong&gt;, named after physicist Enrico Fermi, is the apparent contradiction between the lack of evidence and high probability estimates for the existence of extraterrestrial civilizations. The basic points of the argument, made by physicists Enrico Fermi and Michael H. Hart, are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;There are billions of stars in the galaxy that are similar to the Sun, and many of these stars are billions of years older than the Solar system.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;With high probability, some of these stars have Earth-like planets, and if the Earth is typical, some may have developed intelligent life.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Some of these civilizations may have developed interstellar travel, a step the Earth is investigating now.
Even at the slow pace of currently envisioned interstellar travel, the Milky Way galaxy could be completely traversed in a few million years.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;According to this line of reasoning, the Earth should have already been visited by extraterrestrial aliens. In an informal conversation, Fermi noted no convincing evidence of this, leading him to ask, "Where is everybody?" (&lt;a href="https://en.wikipedia.org/wiki/Fermi_paradox" target="_blank"&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Having studied the vast majority of proposed Fermi paradox solutions, I believe I had found the common misconception that plagues not just them, but multiple seemingly unrelated theories as well. The assumption of rationality.&lt;/p&gt;
&lt;p&gt;But first things first. Why &lt;em&gt;should&lt;/em&gt; we see any signs of alien activity? Because, whatever their logic and motives may be, they should definitely share a common trait: the tendency for growth. It is either included or follows directly from any definition of life. This implies that any life either stops expanding outward at a certain stage, goes extinct, or simply never occurred before. The latter proposition seems extremely improbable given the age of the universe, and the two former ones are more or less the same, since stagnation eventually means running out of energy and dying. The more you think about it, the scarier this idea becomes.&lt;/p&gt;
&lt;p&gt;For now let us assume that our competitors are either dead or never born; that we are the only life within our cosmological horizon; that we are free to make our own choices. &lt;em&gt;Or are we?&lt;/em&gt; Can a civilization really make a deliberate choice, especially one that makes logical sense? If we could, wouldn't we already stop wars, hunger, diseases and climate change? We certainly have the science and resources to do so. So why wouldn't we?&lt;/p&gt;
&lt;p&gt;Because, like any system, society is &lt;em&gt;not&lt;/em&gt; a sum of its members. It is an entity of its own, functioning in accordance with its own rules which couldn't care less about individual humans. Even an ideal totalitarian dictator cannot control the society as a system, let alone the will of the majority. Even though humans are orders of magnitude smarted than ants, &lt;em&gt;humanity&lt;/em&gt; isn't much smarter than an anthill when it comes to making decisions. This is what &lt;a href="https://youtu.be/oo4YAYg68OU" target="_blank"&gt;Noam Chomsky calls "Institutional irrationality"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It actually presents an advantage for science fiction writers: even if it's impossible to imagine a being far smarter than oneself, predicting how those beings will behave as a civilization is very much on the table.&lt;/p&gt;
&lt;p&gt;So, how will &lt;em&gt;humans&lt;/em&gt; behave in the future? To preserve your likely fading attention, I now have to include a chart that explains my vision for the Fermi paradox, that I will then explain step-by-step:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/fermi-paradox/fermi_en.png"&gt;&lt;/p&gt;
&lt;p&gt;We've already concluded that, even if humans aren't the first, other species don't seem to have survived long enough to greet us; so our destiny is up to ourselves. The question then is, "Can we behave rationally?", or "Is there a 'cure' for institutional irrationality?". Both answers lead to fascinating conclusions.&lt;/p&gt;
&lt;p&gt;First, what if we can't? In short term this would mean suffering all the consequences of climate change and possibly a nuclear war, but is that really enough to completely eradicate humanity? I'm not sure about that. Even a small surviving population can quickly rebuild due to information being virtually indestructible at this point. And even if all humans are dead, other species will be happy to take our place. With more than a billion years of mild sunlight remaining, they should have more than enough time to develop intelligence of their own. Hell, they might even evolve space-faring capability through sheer brute force of natural selection! And being wiped out by superintelligent AI only exacerbates the situation, because that AI would have all our faults embedded it its reward function. It would also be life.&lt;/p&gt;
&lt;p&gt;But don't you worry yet, there's another way of destroying ourselves that doesn't rely on sterilizing one particular planet: the way suggested in &lt;a href="https://myanimelist.net/anime/2001/Tengen_Toppa_Gurren_Lagann" target="_blank"&gt;Tengen Toppa Gurren-Lagann&lt;/a&gt;. This must sound like a joke, but bear with me for a while.&lt;/p&gt;
&lt;p&gt;One aspect of institutional irrationality is income inequality. It is not a problem with human civilization in particular, but rather a representation of a more general rule: when tomorrow's state of a variable is directly proportional to today's, its distribution follows &lt;a href="https://en.wikipedia.org/wiki/Pareto_distribution" target="_blank"&gt;Pareto's curve&lt;/a&gt;. There are good reasons to believe that space economy will follow the same rules: the more fuel you have on a spaceship, the further you can go, the more fuel you can mine on-site, etc. What will wealth be measured in? Matter. With advanced enough technology, the kind of matter doesn't make much difference: nearly everything can be used as fuel or construction material. It then naturally follows that everyone would work toward hoarding as much matter as possible and that some will have exponentially more than others. But what happens when you put too much matter in one place, according to relativity?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A black hole happens.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Black holes are the most likely graves for those who came before us, as well as ourselves. A perfect way to make it seem as if we were alone. This isn't even a "Great filter" anymore, but rather a "Great attractor" — the inevitable trap that every civilization has to fall into, sooner or later.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/fermi-paradox/1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;What would be the point of gathering all the matter in such close proximity to enable a collapse? Simply put, protection. The smaller the surface area of an object in space, the easier it is to defend. "Defend from whom?" Again, extrapolation of our present reality yields this answer easily.&lt;/p&gt;
&lt;p&gt;This hypothesis isn't completely untestable, though. Detecting black holes that don't fit our models of galaxy and star formation would be evidence in favor of it. And those black holes &lt;a href="https://physics.aps.org/featured-article-pdf/10.1103/PhysRevLett.116.061102" target="_blank" title="Wow, a link to a legitimate scientific article!"&gt;may actually exist&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Would an entire civilization collapse into that one black hole? Almost certainly not. But those who remain after the catastrophe won't have much resources to rebuild. And when they do rebuild, the same exact catastrophe will repeat. This cycle effectively makes infinite exponential growth — the bedrock of Dyson dilemma, and, consequently, the Fermi paradox — impossible.&lt;/p&gt;
&lt;p&gt;In the process of gathering enough matter we are also likely to devour other inhabited solar systems that haven't yet evolved to our level, the same way a construction crew demolishes anthills before building real estate on their place. The scale of destruction is hard to estimate now, but it might well envelop the entire supercluster. Destroying the entire universe, as suggested by the chart, is theoretically impossible, but it doesn't make much difference. The most obvious counterargument, "But surely an interstellar civilization won't be dumb enough to collapse itself into black holes!", contradicts the assumption we've made by going down this logical branch on the chart above, namely "We can't behave rationally".&lt;/p&gt;
&lt;p&gt;But what if we can?&lt;/p&gt;
&lt;p&gt;Well, even if &lt;em&gt;we&lt;/em&gt; can, &lt;em&gt;others&lt;/em&gt; probably don't. And we cannot sit idly by as some alien species is devouring &lt;em&gt;our&lt;/em&gt; supercluster. The best thing we can do to benefit everyone is to forcefully stagnate their development, trap them in their home solar system before it's too late. At least that seems to be the only alternative to complete eradication of all alien life.&lt;/p&gt;
&lt;p&gt;The Zoo hypothesis and the Matrix now seem much more feasible. Maybe, we aren't alone after all? Maybe, our world isn't really &lt;em&gt;ours&lt;/em&gt;? Actually, that might be the best option of all. In this case, we are alleviated from the privilege of making the hard decisions and hard mistakes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cyberape.space/en/content/posts/fermi-paradox/2.jpg"&gt;&lt;/p&gt;</content><category term="Post"></category></entry></feed>